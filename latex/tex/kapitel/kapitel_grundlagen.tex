\chapter{Grundlagen}\label{ch:grundlagen}

Dieses Kapitel erläutert die wesentlichen Grundlagen, auf denen diese Arbeit aufbaut.
Zunächst werden die rechtlichen Rahmenbedingungen des Urheberrechts untersucht, insbesondere im Hinblick auf Software und die Besonderheiten der Open-Source-Lizenzierung.
Darauf aufbauend werden die technischen Konzepte von \glspl{llm} vorgestellt, welche die technologische Basis für die in dieser Arbeit entwickelte Methode zur Datenextraktion bilden.

% ======================================================================================================================

\section{Rechtliche Grundlagen}\label{sec:rechtliches}

Die zunehmende Verbreitung von \gls{oss} in Forschung, Industrie und öffentlicher Verwaltung wirft eine Vielzahl rechtlicher Fragen auf, die sich insbesondere auf das Urheberrecht und die Lizenzierungspraxis beziehen.
Obwohl \gls{oss} für gewöhnlich frei zugänglich ist, unterliegt sie in Deutschland uneingeschränkt dem Schutz des Urheberrechts gemäß dem \gls{urhg} \autocite{noauthor_urhg_nodate}.
Die rechtssichere Nutzung, Veränderung und Weiterverbreitung quelloffener Software setzt daher ein grundlegendes Verständnis der urheberrechtlichen Schutzmechanismen, der Einräumung und Durchsetzung von Nutzungsrechten sowie der Einhaltung von Lizenzbedingungen voraus.
Gerade im Kontext automatisierter Softwareanalysen, etwa durch \glspl{llm}, rücken Fragen der korrekten Attribution, der Wahrung von Lizenzpflichten und der Erkennbarkeit urheberrechtlicher Hinweise im Code in den Fokus.
Dieses Kapitel beleuchtet die rechtlichen Grundlagen für den Einsatz von \gls{oss}, analysiert spezifische Regelungen des deutschen \gls{urhg} im Bereich von Software, zeigt potenzielle Konflikte innerhalb der Software-Lieferkette und stellt die Konsequenzen urheberrechtlicher Verstöße dar.

% ----------------------------------------------------------------------------------------------------------------------

\subsection{Grundlagen des Urheberrechts}\label{subsec:grundlagen-des-urheberrechts}

Das deutsche Urheberrechtsgesetz schützt die geistigen Schöpfungen von Autoren, Künstlern und anderen Kreativen.
Ziel des Urheberrechts ist es, sowohl die persönlichen als auch die wirtschaftlichen Interessen des Urhebers zu sichern (§ 11 \gls{urhg}).
Die zentrale Voraussetzung für den Schutz ist die sogenannte Schöpfungshöhe, also ein gewisses Maß an Individualität des Werkes.
Ein urheberrechtlicher Schutz entsteht automatisch mit der Schaffung des Werkes, eine Registrierung ist nicht erforderlich.

Gemäß § 2 Absatz 1 \gls{urhg} gehören Computerprogramme ausdrücklich zu den schutzfähigen Werken.
Sie werden unter Nr. 1 als \enquote{Werke der Literatur} erfasst, unabhängig davon, ob sie künstlerisch anspruchsvoll oder lediglich funktional gestaltet sind.
Der Urheber im Sinne des \gls{urhg} ist die natürliche Person, die das Werk geschaffen hat (§ 7 \gls{urhg}).

Für das Verständnis von \gls{oss} ist besonders relevant, dass die Schutzwirkung des Urheberrechts unabhängig davon gilt, ob das Werk kommerziell oder unentgeltlich verwendet werden soll.
Auch öffentlich zugängliche Software unterliegt dem Urheberrecht, und ihre Nutzung bedarf grundsätzlich der Zustimmung des Rechteinhabers (§§ 15 ff. \gls{urhg}).

% ----------------------------------------------------------------------------------------------------------------------

\subsection{Computerprogramme als besondere Werkform (§§ 69a–69g UrhG)}

Im Jahr 1993 wurden durch die §§ 69a bis 69g \gls{urhg} spezielle Regelungen für Computerprogramme in das Gesetz aufgenommen.
Diese Vorschriften basieren auf der EU-Richtlinie 2009/24/EG über den Rechtsschutz von Computerprogrammen.
Software gilt damit als eine eigenständige Werkform mit besonderen Regelungen, die sich in Teilen von den allgemeinen Bestimmungen des Urheberrechts unterscheiden.

Nach § 69a \gls{urhg} sind Programme geschützt, wenn sie eine persönliche geistige Schöpfung des Urhebers darstellen.
Der Schutz bezieht sich nicht nur auf den Quellcode, sondern auch auf vorbereitende Entwurfsunterlagen, sofern sie unmittelbar zur Entwicklung eines Programms bestimmt sind.

§ 69b \gls{urhg} bestimmt, dass der Urheber eines Programms in aller Regel diejenige Person ist, die es entwickelt hat.
Wird die Software jedoch im Rahmen eines Arbeitsverhältnisses erstellt, gehen die uneingeschränkten Nutzungsrechte grundsätzlich auf den Arbeitgeber über.

Die in § 69c \gls{urhg} genannten Rechte des Rechteinhabers umfassen unter anderem das dauerhafte oder vorübergehende Vervielfältigen, Übersetzen, Bearbeiten oder anderweitige Umarbeiten eines Programms sowie dessen öffentliche Wiedergabe.
§ 69d \gls{urhg} regelt die zulässigen Handlungen.
Beispielsweise darf ein rechtmäßiger Nutzer ein Programm vervielfältigen, beobachten, untersuchen oder testen, wenn dies für dessen bestimmungsgemäße Nutzung erforderlich ist.

§ 69e \gls{urhg} erlaubt einem Nutzer unter bestimmten Voraussetzungen die Dekompilierung eines Programms.
Ziel dieser Regelung ist insbesondere die Sicherstellung der Interoperabilität mit anderen Programmen.
Gerade im Open-Source-Kontext kann diese Vorschrift bei der Analyse proprietärer Schnittstellen von Bedeutung sein.

% ----------------------------------------------------------------------------------------------------------------------

\subsection{Einräumung von Nutzungsrechten (§§ 31–33 UrhG)}

Ein zentrales Instrument für die Verbreitung und Nutzung von Software ist die Einräumung von Nutzungsrechten.
Diese ist im Urheberrecht in den §§ 31 bis 33 \gls{urhg} geregelt.
Während das Urheberrecht als solches nicht übertragbar ist (§ 29 Abs. 1 \gls{urhg}), können Nutzungsrechte an einem Werk sehr wohl eingeräumt werden (§ 29 Abs. 2 \gls{urhg}).
Hierbei wird zwischen einfachen und ausschließlichen Nutzungsrechten unterschieden (§ 31 Abs. 1 \gls{urhg}).
Einfache Nutzungsrechte erlauben die gleichzeitige Nutzung durch mehrere Personen, während ausschließliche Rechte eine exklusive Nutzung vorsehen (§ 31 Abs. 2 \gls{urhg}).

Software Lizenzen allgemein und insbesondere Open-Source-Lizenzen wie die \gls{gpl}\footnote{\url{https://www.gnu.org/licenses/gpl-3.0.de.html}}, die MIT License\footnote{\url{https://opensource.org/license/mit}} oder die Apache
License\footnote{\url{https://www.apache.org/licenses/LICENSE-2.0}} gewähren typischerweise einfache Nutzungsrechte.
Diese standardisierten Lizenzverträge werden wirksam, sobald die Software verwendet, weitergegeben oder öffentlich verfügbar gemacht wird.

§ 32 \gls{urhg} regelt die angemessene Vergütung des Urhebers.
Im Bereich von \gls{oss} kommt dieser Vorschrift meist keine praktische Bedeutung zu, da die Lizenzen oft ausdrücklich auf eine Vergütung verzichten.
Dennoch ist rechtlich klar, dass die Unentgeltlichkeit der Nutzung nicht automatisch bedeutet, dass der Urheber auf seine Rechte verzichtet.
Gerade im Kontext von Dual-Lizenzmodellen wird deutlich, dass bei einer Nichtbeachtung der \gls{oss}-Lizenz der Urheber auf die kommerzielle Lizenz verweisen und deren Wert geltend machen kann.

§ 33 \gls{urhg} betrifft die Übertragbarkeit von Rechten.
Diese Vorschrift kann beispielsweise bei der Weitergabe von Projekten, dem Forking oder der Übernahme von \gls{oss}-Komponenten durch Dritte relevant sein.

Ein rechtlich entscheidender Punkt bei Software-Lizenzierung sind die damit verbundenen Verpflichtungen, insbesondere die sogenannten Copyleft-Klauseln, wie sie prominent in der \gls{gpl} zu finden sind.
Diese Klauseln verpflichten den Lizenznehmer, bei einer Weiterverbreitung des Werkes oder davon abgeleiteter Werke, diese ebenfalls unter die Bedingungen der ursprünglichen Lizenz zu stellen.
Diese Verpflichtungen gelten als Bedingungen für die Einräumung der Nutzungsrechte.
Hält sich ein Nutzer nicht an die Nutzungsbedingungen, indem er beispielsweise den Quellcode einer veränderten GPL-Software nicht mitliefert, verfällt die Einräumung der Nutzungsrechte.
Die daraus resultierende Urheberrechtsverletzung wird im Abschnitt \ref{subsec:rechtsfolgen-bei-urheberrechtsverstoen} behandelt.

% ----------------------------------------------------------------------------------------------------------------------

\subsection{Anwendung auf Open Source Software}

\gls{oss} unterliegt dem Urheberrecht oder ähnlichen internationalen Rechten unabhängig davon, ob sie frei oder kostenpflichtig zur Verfügung steht.
Der entscheidende Unterschied zu proprietärer Software besteht darin, dass die Rechteinhaber ihre Nutzungsrechte bewusst in standardisierten Lizenztexten öffentlich freigeben.
Diese Freigabe erfolgt meist in Form einfacher Nutzungsrechte im Sinne von § 31 Abs. 2 \gls{urhg}.

Einige Open-Source-Lizenzen unterscheiden sich vor allem darin, welche Pflichten sie bei der Weiterverbreitung auferlegen.
So erlauben die MIT oder Apache License eine besonders freie Nutzung, auch in proprietären Softwareprodukten, ohne dass der weiterentwickelte oder kombinierte Code selbst wieder unter denselben Lizenzbedingungen veröffentlicht werden muss.
Die \gls{gpl} hingegen schreibt im Rahmen ihres Copyleft-Prinzips vor, dass abgeleitete Werke oder Weitergaben ebenfalls unter den Bedingungen der \gls{gpl} offengelegt werden müssen.
Durch diese Copyleft-Klauseln sind Lizenzen wie die \gls{gpl} für proprietäre Softwareentwicklung weitestgehend ungeeignet.

Open Source kann somit entweder auf vertraglicher Grundlage oder, in bestimmten Fällen, durch gesetzliche Schranken genutzt werden.
Voraussetzung ist stets, dass die Bedingungen eingehalten und die Verpflichtungen erfüllt werden.

% ----------------------------------------------------------------------------------------------------------------------

\subsection{Rechtsfolgen bei Urheberrechtsverstößen}\label{subsec:rechtsfolgen-bei-urheberrechtsverstoen}

Die Verletzung urheberrechtlicher Vorschriften oder die Nichtbeachtung von Lizenzbedingungen kann weitreichende rechtliche Folgen haben.
Nach § 97 \gls{urhg} hat der Urheber Anspruch auf Unterlassung und Beseitigung der Beeinträchtigung.
Darüber hinaus kann ein Anspruch auf Schadensersatz bestehen, der je nach Sachlage entweder auf dem konkreten Schaden, dem Gewinn des Verletzers oder einer fiktiven Lizenzgebühr basiert.

§ 98 \gls{urhg} ermöglicht es zudem, rechtswidrig hergestellte oder verbreitete Vervielfältigungsstücke zu vernichten oder vom Markt zu nehmen.
In besonders schweren Fällen sind strafrechtliche Sanktionen nach § 106 \gls{urhg} möglich, etwa bei vorsätzlicher und gewerbsmäßiger Verletzung des Urheberrechts.
Wer \gls{oss} einsetzt oder weiterverbreitet, trägt daher die Verantwortung, die jeweiligen Lizenzbedingungen genau zu beachten und die geltenden Verpflichtungen zu erfüllen.
Wird beispielsweise eine Lizenzbedingung der \gls{gpl} verletzt, etwa durch Nichtoffenlegung des Quellcodes, kann die Lizenzwirkung entfallen.
In diesem Fall ist jede weitere Nutzung als unrechtmäßige Verwertung zu bewerten, mit allen sich daraus ergebenden rechtlichen und wirtschaftlichen Konsequenzen.

% ----------------------------------------------------------------------------------------------------------------------

\subsection{Copyright-Vermerke und Autorenkennzeichen im Quellcode}

In der Open-Source-Softwareentwicklung ist es üblich, urheberrechtlich relevante Informationen direkt im Quellcode zu vermerken.
Dazu zählen Copyright-Hinweise, Autorenkennzeichen und Lizenzvermerke.
Diese Informationen dienen nicht der Entstehung des Urheberrechts, das automatisch mit der Schöpfung eines Werkes entsteht (§ 7 UrhG), erfüllen jedoch eine bedeutende Funktion.
Sie ermöglichen die Zurechnung von Urheberschaft, stellen sicher, dass Lizenzbedingungen bekannt gemacht werden, und unterstützen die Einhaltung der rechtlichen Rahmenbedingungen bei der Weitergabe.
Durch standardisierte Angaben wie SPDX-License-Identifier\footnote{\url{https://spdx.dev/learn/handling-license-info/}} können solche Informationen zudem maschinell ausgelesen werden.

% ----------------------------------------------------------------------------------------------------------------------

\subsection{Auswirkungen auf die Software-Lieferkette}

Die zunehmende Verwendung von \gls{oss} in komplexen IT-Systemen führt dazu, dass Softwareprodukte häufig auf der Basis zahlreicher externer Komponenten aufgebaut werden.
Daraus ergeben sich rechtlich relevante Abhängigkeiten innerhalb der Software-Lieferkette.

Jede dieser Komponenten unterliegt bestimmten Nutzungsbedingungen, die über die jeweilige Lizenz definiert sind.
Werden diese Bedingungen nicht eingehalten, etwa durch Nichtbeachtung von Namensnennungspflichten oder durch unzulässige Integration in proprietäre Systeme, kann dies dazu führen, dass das Nutzungsrecht erlischt und eine Urheberrechtsverletzung vorliegt (§ 97 UrhG).

Für Unternehmen und Entwickler bedeutet dies, dass alle eingebundenen Komponenten erfasst, die Lizenzierung geprüft und die Ergebnisse dokumentiert werden müssen.
Die Anforderungen an die Compliance steigen mit der Komplexität des Produkts.
%Hier können automatisierte Verfahren, etwa auf Basis von \glspl{llm}, eine große Unterstützung bieten, indem sie Lizenztexte analysieren, Copyright-Vermerke erkennen und auf potenzielle Verstöße hinweisen.

% ----------------------------------------------------------------------------------------------------------------------

\subsection{Internationale Urheberrechtsregelungen}

Die rechtliche Einbettung des Urheberrechts ist nicht allein national geregelt.
Vielmehr beruht der urheberrechtliche Schutz weltweit auf einer Reihe völkerrechtlicher Übereinkommen, die Mindeststandards und Grundprinzipien für den Schutz geistigen Eigentums festlegen.
Eine der wichtigsten Grundlagen bildet das sogenannte \gls{wua}, das 1952 in Genf verabschiedet wurde.
Es legt fest, dass in jedem Vertragsstaat ausländische Urheber ebenso behandelt werden wie Inländer, sofern der Herkunftsstaat ebenfalls Vertragspartei ist.
Dieses Prinzip der Inländerbehandlung (\enquote{national treatment}) stellt sicher, dass urheberrechtliche Ansprüche grenzüberschreitend durchsetzbar sind \autocite{meckel_definition_nodate}.

Außerdem von Bedeutung ist die \gls{rbü}, die auf das Jahr 1886 zurückgeht und seither mehrfach angepasst wurde.
Sie garantiert dem Urheber bestimmte Mindestschutzrechte, etwa das Recht auf Urheberschaftsnennung, das Verbot der Werksverfälschung und ein wirtschaftliches Verwertungsrecht für mindestens 50 Jahre nach dem Tod des Urhebers.
Die \gls{rbü} verpflichtet Vertragsstaaten, diese Rechte in ihren nationalen Rechtsordnungen zu verankern, wobei der Schutz automatisch mit der Schöpfung des Werkes eintritt und keiner Registrierung bedarf \autocite{meckel_definition_nodate-1}.

Die Bundesrepublik Deutschland ist dieser Übereinkunft am 1.\ August 1955 beigetreten.
Ihre Umsetzung ist im nationalen Recht unter anderem durch das Urheberrechtsgesetz erfolgt.
Die deutsche Version des Vertrags findet sich unter anderem im Bundesgesetzblatt sowie auf der Website des Bundesministeriums der Justiz\footnote{\url{https://www.gesetze-im-internet.de/\_bkbern\_berlinav}}.

Ergänzend hierzu ist das \gls{trips} zu nennen, das im Rahmen der \gls{wto} 1994 abgeschlossen wurde.
Es verpflichtet alle \gls{wto}-Mitgliedstaaten zur Einhaltung zentraler Bestimmungen der \gls{rbü} (mit Ausnahme der Urheberpersönlichkeitsrechte) und bildet damit einen völkerrechtlichen Mindeststandard auch für Staaten, die der \gls{rbü} oder dem \gls{wua} nicht beigetreten sind \autocite{malbon_standards_2014}.

Diese internationalen Regelungen sind nicht zuletzt deshalb relevant, weil \gls{oss} regelmäßig grenzüberschreitend entwickelt und verbreitet wird.
Die Kenntnis dieser völker- und handelsrechtlichen Rahmenbedingungen ist somit für die rechtssichere Nutzung von Software in internationalen Zusammenhängen entscheidend.

% ======================================================================================================================

\section{Large Language Models}

\glspl{llm} stellen einen zentralen Forschungsgegenstand der künstlichen Intelligenz dar und finden zunehmend Anwendung in digitalen Systemen.
Ihre Entwicklung basiert auf einer Reihe fundamentaler wissenschaftlicher Arbeiten.

Die technologische Grundlage heutiger \glspl{llm} wurde durch die Abkehr von \glspl{rnn} geschaffen.
Diese waren in ihrer Fähigkeit, lange sequenzielle Abhängigkeiten zu modellieren, limitiert und nur bedingt für paralleles Rechnen geeignet \autocite{vaswani_attention_2023}.
Ein entscheidender Fortschritt war die Einführung der Transformer-Architektur durch \citeauthor{vaswani_attention_2023} \autocite{vaswani_attention_2023}.
Anstelle einer sequenziellen Verarbeitung von Informationen implementiert der Transformer einen Self-Attention-Mechanismus.
Dieser ermöglicht es dem Modell, die kontextuellen Beziehungen aller Elemente einer Eingabesequenz simultan zu gewichten.
Diese Architektur bietet zwei wesentliche Vorteile: Sie erlaubt eine hohe Parallelisierbarkeit des Trainingsprozesses auf entsprechender Hardware und verbessert die Modellierung von langreichweitigen Abhängigkeiten in der Eingabesequenz \autocite{vaswani_attention_2023}.

Aufbauend auf dieser Architektur wurden in den folgenden Jahren spezialisierte Modellvarianten entwickelt, die entscheidend zur heutigen Leistungsfähigkeit von \glspl{llm} beigetragen haben.
Ein bedeutender Meilenstein war die Veröffentlichung von \gls{bert} durch \citeauthor{devlin_bert_2019} \autocite{devlin_bert_2019}.
\gls{bert} nutzt ausschließlich den Encoder-Teil des Transformers und wurde darauf ausgelegt, kontextuelle Wortrepräsentationen bidirektional zu erfassen.
Dies geschieht durch das sogenannte \gls{mlm}, bei dem einzelne Token einer Eingabesequenz maskiert und vom Modell vorhergesagt werden müssen.
Ein Token bezeichnet dabei eine kleinste Verarbeitungseinheit von Text, die je nach Modell ein einzelnes Zeichen, eine Silbe oder ein ganzes Wort umfassen kann.
Dadurch kann \gls{bert} semantische Beziehungen sowohl aus vorangehenden als auch nachfolgenden Kontexten ableiten, was zu erheblichen Leistungssteigerungen bei einer Vielzahl von Aufgaben des \gls{nlp} führt, etwa bei Fragebeantwortung oder semantischer Textklassifikation \autocite{devlin_bert_2019}.

Parallel zur Weiterentwicklung von Encoder-basierten Modellen etablierten sich auch großskalige autoregressive Sprachmodelle, die auf dem Decoder-Teil der Transformer-Architektur beruhen.
Ein herausragendes Beispiel ist \gls{gpt}-3 von \citeauthor{brown_language_2020} \autocite{brown_language_2020}.
\gls{gpt}-3 verfolgt einen rein autoregressiven Ansatz, bei dem das nächste Token auf Grundlage der vorangegangenen Token vorhergesagt wird.
Durch eine massive Skalierung der Modellparameter (auf 175 Milliarden) sowie des Trainingskorpus auf Hunderte Milliarden Token konnte \gls{gpt}-3 eine bemerkenswerte Fähigkeit zur Textgenerierung, Aufgabenadaption und kontextabhängigen Inferenz ohne explizites Fine-Tuning demonstrieren (\nameref{subsec:in-context-learning}).
Diese Entwicklung verdeutlichte, dass die Leistungsfähigkeit von \glspl{llm} nicht nur von der Transformer-Architektur, sondern maßgeblich auch von der Trainingsdatenmenge und der Modellgröße beeinflusst wird.

Aktuelle \glspl{llm} unterscheiden sich von früheren Modellen wie \gls{bert} und \gls{gpt}-3 vor allem durch ihre Multimodalität, deutlich größere Kontextfenster, verbesserte Reasoning-Fähigkeiten und effizientere Architekturdesigns.
Während \gls{bert} primär für textbasierte Aufgaben mit bidirektionalem Kontextverständnis entwickelt wurde und \gls{gpt}-3 vor allem auf autoregressive Textgenerierung in großem Maßstab setzte, können moderne Modelle oft Text, Bilder und andere Eingabeformen verarbeiten und komplexere logische Schlüsse ziehen.
Ein Beispiel hierfür ist Gemini 2.5 Pro\footnote{\url{https://gemini.google.com}}, das multimodale Eingaben unterstützt, ein Kontextfenster von über einer Million Tokens bietet und für schrittweises Denken optimiert wurde.
% ----------------------------------------------------------------------------------------------------------------------

\subsection{Natural Language Processing (NLP)}

\gls{nlp} befasst sich mit der automatisierten Erkennung, Verarbeitung und Analyse natürlicher Sprache.
Ziel ist es, die Kommunikation zwischen Mensch und Maschine in natürlicher Sprache zu ermöglichen, Übersetzungen zu erleichtern und große Mengen an Text effizient auszuwerten.
Frühere Ansätze setzten dabei auf klar voneinander getrennte Verarbeitungsschritte, etwa der Segmentierung eines Textes in kleinere Einheiten, die Bestimmung der Wortarten oder die Analyse der Satzstruktur.
Besonders herausfordernd ist die Syntaxanalyse, da sie die grammatische Struktur eines Satzes präzise erfassen muss, um die Beziehungen zwischen einzelnen Wörtern und Satzteilen korrekt zu modellieren.
Die hohe Komplexität natürlicher Sprache, die sich in Mehrdeutigkeit, Kontextabhängigkeit und schwer erkennbaren Phänomenen wie Ironie zeigt, macht dieses Gebiet zu einem der anspruchsvollsten innerhalb der Informatik.
Gleichzeitig ist die Fähigkeit, Sprache als intuitive Schnittstelle zwischen Mensch und Maschine zu nutzen, eine zentrale Voraussetzung für die Verbreitung moderner Assistenzsysteme, da alternative Steuerungsformen oft zu umständlich sind \autocite{grigoleit_natural_2019}.

Moderne \glspl{llm} vereinen viele dieser Analyse- und Verarbeitungsschritte in einem einzigen Modell.
Sie können sowohl semantische als auch syntaktische Zusammenhänge über große Textkontexte hinweg erkennen und verarbeiten, wodurch sie in Bereichen wie maschineller Übersetzung, automatischer Fragebeantwortung und Stimmungsanalyse deutlich bessere Ergebnisse erzielen als traditionelle Systeme.

% ----------------------------------------------------------------------------------------------------------------------

\subsection{In-Context Learning (ICL)}\label{subsec:in-context-learning}

Ein wesentlicher Grund für die hohe Leistungsfähigkeit moderner \glspl{llm} im Bereich \gls{nlp} liegt in ihrer Fähigkeit zum sogenannten \enquote{In-Context Learning}.
Dabei wird das Modell nicht durch eine separate Trainingsphase auf eine spezifische Aufgabe angepasst, sondern erhält die Aufgabenbeschreibung direkt im Eingabetext.
Dieser kann aus einer Anweisung in natürlicher Sprache bestehen oder zusätzlich ausgewählte Beispiele enthalten, die das gewünschte Vorgehen verdeutlichen.
Auf dieser Grundlage wird das Modell so konditioniert, dass es weitere Instanzen der Aufgabe allein durch Vorhersage des nächsten Tokens lösen kann.
Dieses Verfahren ermöglicht eine flexible Anpassung an eine Vielzahl von Aufgaben, ohne dass das Modell für jede einzelne neu trainiert werden muss, und stellt damit einen zentralen Mechanismus dar, durch den \glspl{llm} in vielen \gls{nlp}-Anwendungsfeldern effektiv eingesetzt werden können \autocite{brown_language_2020}.

% ----------------------------------------------------------------------------------------------------------------------

\subsection{Named Entity Recognition (NER)}

Die \gls{ner} ist eine grundlegende Aufgabe des \gls{nlp}, bei der benannte Entitäten wie Personennamen, Organisationen, Orte oder Datumsangaben in Texten erkannt und vordefinierten Kategorien zugeordnet werden.
Sie dient dazu, strukturierte Informationen aus unstrukturierten Texten zu extrahieren und bildet damit eine zentrale Grundlage für viele weiterführende Anwendungen wie \gls{ie}, Fragebeantwortung oder Zusammenfassungen.
Für die Umsetzung von \gls{ner} existieren unterschiedliche methodische Ansätze \autocite{pakhale_comprehensive_2023}.

Regelbasierte Verfahren arbeiten mit explizit definierten sprachlichen oder domänenspezifischen Mustern, während überwachte Lernverfahren auf annotierten Datensätzen trainiert werden, um Entitäten anhand gelernter Muster zu erkennen.
Unüberwachte Ansätze hingegen nutzen kleine Mengen von Startbeispielen, um iterativ neue Erkennungsmuster zu generieren.
Moderne Systeme setzen zunehmend auf Transformer-Modelle wie \gls{bert}, die durch kontextualisierte Wortrepräsentationen auch komplexe Abhängigkeiten und semantische Feinheiten erfassen können \autocite{pakhale_comprehensive_2023}.

Anwendungsfelder von \gls{ner} finden sich unter anderem in der Verarbeitung juristischer Dokumente \autocite{breton_empowering_2024}, der Extraktion medizinischer Fachtermini \autocite{islam_llm-based_2025}, der Analyse biologischer Fachliteratur \autocite{lee_biobert_2020} oder der Auswertung von Social-Media-Inhalten \autocite{niu_osint_2025}.
\glspl{llm} erweitern diese Möglichkeiten, indem sie entweder durch gezieltes Fine-Tuning \autocite{dunn_structured_2022} auf spezifische \gls{ner}-Domänen angepasst oder mittels Prompt-basierten Zero- und Few-Shot-Verfahren \autocite{villena_llmner_2024,cheng_novel_2024,wei_chatie_2024} eingesetzt werden.
Dadurch lassen sich selbst mit wenig oder gar keinem zusätzlichen Trainingsmaterial robuste Erkennungsleistungen erzielen, was insbesondere für ressourcenarme Sprachen und dynamische Anwendungsgebiete von Vorteil ist \autocite{pakhale_comprehensive_2023}.

% ----------------------------------------------------------------------------------------------------------------------

\subsection{Prompt-Engineering}

Prompt-Engineering bezeichnet die gezielte Gestaltung und Anpassung von Eingaben für \glspl{llm}, um deren Ausgabequalität zu beeinflussen.
Ziel ist es, Anweisungen in natürlicher Sprache so zu formulieren, dass das Modell präzise, kontextbezogene und für den jeweiligen Anwendungsfall geeignete Ergebnisse erzeugt.
Eine sorgfältige Ausgestaltung der Eingabe kann die Interaktion zwischen Nutzer und Modell strukturierter und nachvollziehbarer gestalten \autocite{chan_generative_2024}.

Im Kontext von \glspl{llm} spielt Prompt Engineering eine wichtige Rolle bei Zero-Shot- und Few-Shot-Ansätzen.
Beim Zero-Shot-Lernen erhält das Modell lediglich eine Aufgabenbeschreibung und bearbeitet die Aufgabe ohne weitere Beispiele.
Beim Few-Shot-Lernen werden zusätzlich einige ausgewählte Beispiele in den Prompt integriert, um dem Modell die Struktur und den gewünschten Stil der Ausgabe zu verdeutlichen.
Beide Ansätze nutzen das Prinzip des \gls{icl}, bei dem das Modell die im Prompt enthaltenen Informationen unmittelbar für die Generierung seiner Ausgabe verwendet, ohne dass eine gesonderte Anpassung der Modellparameter erforderlich ist \autocite{villena_llmner_2024}.

Durch die Kombination aus klaren Anweisungen, relevanten Kontextinformationen und gegebenenfalls Beispielen kann Prompt-Engineering die Leistungsfähigkeit moderner \glspl{llm} in unterschiedlichen Anwendungsbereichen unterstützen.

% ----------------------------------------------------------------------------------------------------------------------

\subsection{Fine-Tuning und Low-Rank Adaptation}

Neben Prompt-Engineering stellt das Fine-Tuning eine zentrale Methode dar, um \glspl{llm} an spezifische Aufgaben oder Domänen anzupassen.
Dies erfolgt, indem ein vortrainiertes \gls{llm} mit zusätzlichen, meist domänenspezifischen Trainingsdaten weitertrainiert wird.
Dabei werden die bestehenden Modellparameter aktualisiert, um die statistischen Eigenschaften der neuen Daten zu berücksichtigen und die Leistung in der Zielaufgabe zu verbessern.
Dieser Prozess kann vollständig erfolgen, indem alle Parameter optimiert werden, oder partiell, indem nur ausgewählte Schichten des Modells angepasst werden \autocite{hu_lora_2021}.

Das vollständige Fine-Tuning großer Sprachmodelle ist jedoch mit erheblichem Rechen- und Speicheraufwand verbunden.
\citeauthor{hu_lora_2021} stellen mit der \gls{lora} einen ressourcenschonenden Ansatz vor, bei dem die Gewichte des vortrainierten Modells eingefroren bleiben und lediglich zusätzlich eingefügte, niedrig-rangige Matrizen während des Trainings optimiert werden \autocite{hu_lora_2021}.
Diese Technik reduziert den Speicherbedarf und die Trainingszeit erheblich, ohne die Modellleistung signifikant zu beeinträchtigen.

% ----------------------------------------------------------------------------------------------------------------------

\subsection{Knowledge Distillation (KD)}

Ein weiterer Ansatz zur Effizienzsteigerung ist die \gls{kd}.
Dabei wird das Wissen eines großen, leistungsstarken \glspl{llm} (Teacher-Model) auf ein kleineres Modell (Student-Model) übertragen.
Hierzu werden identische Eingaben beiden Modellen präsentiert, und das Student-Model wird auf die vom Teacher-Model erzeugten Ausgaben und Wahrscheinlichkeitsverteilungen trainiert.
Auf diese Weise kann das kleinere Modell die Verhaltensmuster und Generalisierungsfähigkeiten des größeren Modells übernehmen, während Rechen- und Speicheranforderungen deutlich reduziert werden.
Dieses Verfahren ist besonders relevant für den Einsatz von \glspl{llm} auf Geräten mit begrenzten Ressourcen oder in Echtzeitanwendungen \autocite{xu_survey_2024}.

% ----------------------------------------------------------------------------------------------------------------------

\subsection{Quantisierung}

Die \gls{glos:quantisierung} ist eine weitere Methode zur Reduktion von Rechen- und Speicheranforderungen von \glspl{llm}.
Dabei werden die hochpräzisen Fließkommazahlen, mit denen die Modellparameter gespeichert sind, durch Darstellungen mit geringerer numerischer Präzision ersetzt, beispielsweise 8-Bit- oder 4-Bit-Formate.
Durch diese Reduktion der Bitbreite sinkt der Speicherbedarf signifikant.
Darüber hinaus verkürzt sich auch die Ausführungszeit, da arithmetische Operationen auf niedrigeren Präzisionsstufen effizienter ausgeführt werden können \autocite{egashira_exploiting_2024}.

Quantisierte \glspl{llm} ermöglichen insbesondere die lokale Ausführung auf Hardware mit begrenzten Ressourcen, wie etwa auf Workstations, Laptops oder sogar mobilen Endgeräten.
\citeauthor{egashira_exploiting_2024} betonen, dass moderne Quantisierungstechniken in der Lage sind, die Genauigkeit des ursprünglichen Modells weitgehend zu erhalten, sodass auch komplexe \gls{nlp}-Aufgaben lokal mit vertretbarem Qualitätsverlust durchgeführt werden können \autocite{egashira_exploiting_2024}.
Durch die Kombination mit anderen Effizienzmethoden wie \gls{lora} oder \gls{kd} lassen sich so flexible und ressourcenschonende Bereitstellungsszenarien für \glspl{llm} realisieren.


