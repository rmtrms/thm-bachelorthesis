\chapter{Fine-Tuning}\label{ch:fine-tuning}

Aufbauend auf den Ergebnissen des Prompt-Engineerings wird in diesem Kapitel das Training eines \gls{llm} für die Extraktion von Copyright-Statements untersucht.
Da das vollständige Fine-Tuning von \glspl{llm} mit erheblichem Ressourcenaufwand verbunden ist, wird stattdessen ein Ansatz mit \gls{lora} gewählt.
Um den Speicherbedarf weiter zu reduzieren und die Effizienz zu erhöhen, wird das Training mit quantisierten \glspl{llm} durchgeführt (QLoRA).

Ziel dieser Untersuchung ist es herauszufinden, ob ein Modell durch Fine-Tuning in der Lage ist, die Anforderungen einer Policy implizit aus umfangreichen Beispieldaten zu lernen, wodurch auf explizite Instruktionen, wie sie beim Prompt-Engineering erforderlich waren, verzichtet werden kann.

\section{Durchführung}

Für die Umsetzung des Fine-Tunings wird das Framework MLX\footnote{\url{https://github.com/ml-explore/mlx}} von Apple eingesetzt, das speziell für Apple-Silicon-Prozessoren optimiert ist.
Die Experimente wurden auf derselben Hardware durchgeführt wie die vorangegangenen Untersuchungen (Mac Mini M4 Pro).

Die Vorgehensweise orientierte sich maßgeblich an den Referenzimplementierungen aus dem MLX-Examples-Repository\footnote{\url{https://github.com/ml-explore/mlx-examples}}.
Voraussetzung für das Training ist ein Datensatz im JSONL-Format, der in die drei Kategorien \textit{train}, \textit{test} und \textit{valid} gegliedert wird.

\begin{itemize}
    \item \textit{train} enthält die Daten, mit denen das Modell tatsächlich trainiert wird. Nach Empfehlung von MLX sollten etwa \num{80} \% der Gesamtdaten in diesem Teil enthalten sein.
    \item \textit{test} dient der Evaluierung der Trainingsleistung auf bislang ungesehenen Daten und sollte rund \num{10} \% des Datensatzes umfassen.
    \item \textit{valid} wird für die fortlaufende Validierung während des Trainings genutzt. In regelmäßigen Abständen wird so überprüft, ob das Modell die gewünschten Lernfortschritte macht.
\end{itemize}
Jede Zeile des Datensatzes enthält einen Eingabeprompt sowie die dazugehörige erwartete Ausgabe.
Das Training erfolgt, indem das Modell lernt, aus der Eingabe die gewünschte Ausgabe korrekt zu generieren.
Im Gegensatz zur Prompt-Engineering-Lösung wird hierbei keine ausführliche Aufgabenbeschreibung vorgegeben, sondern lediglich eine allgemeine Instruktion.
Diese Instruktion kann bei der Inferenz genutzt werden, um das erlernte Verhalten zuverlässig abzurufen.

MLX stellt verschiedene Parameter zur Steuerung des Trainings bereit.
Von besonderer Bedeutung waren:

\begin{itemize}
    \item \textit{LoRA-Layers}: legt die Anzahl der trainierbaren LoRA-Schichten fest und bestimmt damit die Menge der anzupassenden Gewichte.
    \item \textit{iterations}: gibt an, wie viele Trainingszyklen durchgeführt werden. Pro Iteration wird jeweils ein Batch an Trainingsdaten verarbeitet.
    \item \textit{learning-rate}: bestimmt die Geschwindigkeit, mit der die Modellgewichte angepasst werden.
\end{itemize}

Alle weiteren Parameter wurden unverändert auf den Standardwerten belassen, da eine umfassende Analyse und Optimierung dieser Einstellungen den Rahmen der Arbeit überschritten hätte.

\subsection{Durchführung mit kuratierten Daten}

Für den ersten Fine-Tuning-Durchlauf wurde ein Datensatz verwendet, der ausschließlich aus manuell kuratierten Beispielen der Kategorie \textit{manually checked} bestand.
Der Datensatz umfasst \num{500} qualitativ hochwertige Einträge, die ein breites Spektrum der in der Policy definierten Regeln abdeckten.

Als Basis für das Fine-Tuning wurde das Modell \texttt{mistral-7B-Instruct-v0.3}\footnote{\url{https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3}} ausgewählt.
Dieses Modell weist eine enge Verwandtschaft zu \texttt{mistral-small:24b} auf, das im Benchmark besonders gute Ergebnisse erzielt hat.
Darüber hinaus handelt es sich um eine Instruct-Variante.
Im Gegensatz zu reinen Basismodellen, die primär auf die Fortsetzung von Text trainiert sind, werden Instruct-Modelle zusätzlich darauf optimiert, Anweisungen präzise zu befolgen und strukturierte Ausgaben zu erzeugen.
Diese Fähigkeit macht sie besonders für Aufgaben wie \gls{ner} geeignet und stellt daher eine geeignete Ausgangsbasis für die vorliegende Untersuchung dar.

Das initiale Training erfolgte mit den Standardparametern von MLX.
Es wurde eine Lernrate von $2 \times 10^{-5}$ bei insgesamt \num{800} Iterationen verwendet.
Obwohl die von MLX bereitgestellten Trainings- und Evaluationsmetriken auf einen erfolgreichen Verlauf hindeuteten, zeigten die praktischen Ausgaben des Modells deutliche Defizite.
Die generierten Ergebnisse bestanden überwiegend aus zusammenhangslosen und unstrukturierten Textfragmenten, die häufig Code-Anteile enthielten und nicht den erwarteten Extraktionen entsprachen.
Auch die anschließende Manipulation der Lernrate, Lora-Schichten und Iterationen bewirkte keine Verbesserung.

\subsection{Durchführung mit generierten Daten}

Die Beobachtungen der ersten Durchführung deuten darauf hin, dass die Größe des verwendeten Datensatzes nicht ausreicht, um ein erfolgreiches Fine-Tuning durchzuführen.
Für die zweite Durchführung wurde daher ein erweiterter Datensatz erstellt.
Zunächst wurden 2000 Dateien der Kategorie \textit{single copyrights without authors} sowie 2000 Dateien der Kategorie \textit{single copyrights with authors} zufällig ausgewählt.
Anschließend wurde die im Kapitel~\ref{ch:prompt-engineering} entwickelte Lösung eingesetzt, um für diese insgesamt 4000 Dateien die Copyright-Informationen zu extrahieren.

Die Eignung dieses Ansatzes basiert auf den zuvor erzielten Ergebnissen, die gezeigt haben, dass die Prompt-Engineering-Lösung bei ungesehenen Daten in der Kategorie \textit{single copyrights} eine Extraktionsgenauigkeit von \num{99} \% an \textit{Exact Matches} erreichen konnte.
Es ist daher davon auszugehen, dass die generierten Trainingsdaten eine hinreichend hohe Qualität aufwiesen, um für ein Fine-Tuning geeignet zu sein.

Der so erstellte Datensatz wurde für das Fine-Tuning des Modells \texttt{mistral-7B-Instruct-v0.3} verwendet.
Das Training erfolgte mit 16 LoRA-Schichten, einer Lernrate von $2 \times 10^{-5}$ und \num{1600} Iterationen, während alle übrigen Parameter unverändert auf den Standardwerten belassen wurden.
Das Modell reagierte nach Abschluss des Trainings korrekt auf die in den Trainingsdaten vorgegebene Instruktion und erzeugte sämtliche Ausgaben konsistent im JSON-Format, ohne Abweichung in der Repräsentation des Formats zu erzeugen.
Die genauen Ergebnisse werden im Abschnitt~\ref{sec:lora-ergebnisse} aufgezeigt.
Der aus dem Training resultierende LoRA-Adapter wurde auf der Plattform Hugging Face\footnote{\url{https://huggingface.co}} veröffentlicht und steht dort zum Download zur Verfügung\footnote{\url{https://huggingface.co/metaeffekt/copyright-scanner-mistral-7b-instruct-v0.3}}.

Da das Fine-Tuning mit einem Modell der Größe von sieben Milliarden Parametern bereits vielversprechende Ergebnisse lieferte, wurde im Anschluss untersucht, ob sich ähnliche Resultate auch mit einem deutlich kleineren Modell erzielen lassen.
Hierfür wurde das Instruct-Modell \texttt{Qwen2.5-1.5B-Instruct}\footnote{\url{https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct}} ausgewählt.
Das Training erfolgte unter identischen Bedingungen wie zuvor, mit dem Unterschied, dass 28 LoRA-Schichten trainiert wurden, was der maximal möglichen Anzahl bei \texttt{Qwen2.5-1.5B-Instruct} entspricht.
Die Erhöhung der LoRA-Schichten wurde vorgenommen, da das verhältnismäßig kleine \gls{llm} weniger Arbeitsspeicher beim Training beansprucht, was die Möglichkeit eröffnete, die volle Anzahl der verfügbaren Schichten zu verwenden.
Auch dieses Modell war nach Abschluss des Trainings imstande, das korrekte Ausgabeformat zuverlässig zu erzeugen.
Der entsprechende Adapter für dieses Modell wurde ebenfalls auf Hugging Face veröffentlicht\footnote{\url{https://huggingface.co/metaeffekt/copyright-scanner-qwen2.5-1.5b-instruct}}.

Die Ergebnisse der trainierten Modelle werden im folgenden Abschnitt mit den Resultaten der Prompt-Engineering-Lösung verglichen.

\section{Ergebnisse}\label{sec:lora-ergebnisse}

Für die abschließende Bewertung und den Vergleich der Modelle wurde der kuratierte Datensatz herangezogen, der aus \num{200} Dateien der Kategorie \textit{exact matches without authors} besteht.
Dieser Datensatz wurde bereits im Kapitel~\ref{ch:benchmark} verwendet, um die Generalisierbarkeit der Prompt-Engineering-Lösung auf ungesehenen Daten zu analysieren.
Dadurch wurde eine direkte Vergleichbarkeit der Ergebnisse sichergestellt.

Zur Bewertung der Leistung werden die beiden fine-tuned \glspl{llm} mit der Prompt-Engineering-Lösung aus dem vorherigen Kapitel verglichen.
Die zentralen Metriken sind dabei die Qualität der Extraktion, gemessen am prozentualen Anteil der\textit{Exact Matches}, und die Verarbeitungsgeschwindigkeit in \textit{Tokens/sec}.
Tabelle~\ref{tab:modellvergleich} fasst die Ergebnisse zusammen.

\begin{table}[H]
    \centering
    \begin{tabular}{l c c}
        \hline
        \textbf{Modell} & \textbf{Exact Matches (\%)} & \textbf{Tokens/sec} \\
        \hline
        \texttt{mistral-small:24b} & 99,0 & 6,02 \\
        \texttt{mistral:7b-instruct-v0.3-fine-tuned} & 99,0 & 20,93 \\
        \texttt{qwen2.5-1.5b-instruct-fine-tuned} & 91,5 & 71,53 \\
        \hline
    \end{tabular}
    \caption{Vergleich der fine-tuned Modelle mit der Prompt-Engineering-Lösung hinsichtlich Genauigkeit und Geschwindigkeit.}
    \label{tab:modellvergleich}
\end{table}

Wie die Ergebnisse zeigen, erbringt das Modell \texttt{mistral:7b-instruct-v0.3-fine"=tuned} eine herausragende Leistung.
Mit einem Anteil von \num{99} \% an \textit{Exact Matches} erreicht es exakt dieselbe Genauigkeit wie das deutlich größere \texttt{mistral-small:24b}.
Gleichzeitig ist die Verarbeitungsgeschwindigkeit mit rund \num{21} \textit{Tokens/sec} mehr als dreimal so hoch wie bei der Prompt-Engineering-Lösung mit ca. \num{6} \textit{Tokens/sec}.
Dieses Ergebnis belegt, dass das Modell die impliziten Regeln der Policy erfolgreich aus den Trainingsdaten erlernen konnte und dabei eine signifikante Effizienzsteigerung erzielt.

Das deutlich kleinere Modell \texttt{qwen2.5-1.5b-instruct-fine-tuned} stellt einen Kompromiss zwischen Genauigkeit und Geschwindigkeit dar.
Die Genauigkeit der Extraktionen sinkt auf \num{91,5} \%, was eine merkliche Reduzierung im Vergleich zu den beiden Mistral-Modellen darstellt.
Im Gegenzug erreicht es mit über \num{71} \textit{Tokens/sec} eine deutlich höhere Verarbeitungsgeschwindigkeit.
Es ist damit mehr als elfmal so schnell wie die ursprüngliche Prompt-Engineering-Lösung.

Ein wesentlicher Vorteil der fine-tuned Modelle liegt in der Vereinfachung der Inferenz.
Statt eines komplexen Prompts von rund 1660 Tokens, wie er für die Prompt-Engineering-Lösung erforderlich war, genügt nun die einfache Anweisung: \enquote{Extract the copyrights, holders and authors in JSON format from the following file} (ca. 20 Tokens).
Zudem erzeugen die Modelle konsistent gültige JSON-Ausgaben, wodurch eine nachgelagerte Korrektur durch Parsing-Mechanismen entfällt.

Zusammenfassend lässt sich festhalten, dass das Fine-Tuning erfolgreich war.
\texttt{Mistral-7B-Instruct-v0.3} stellt die optimale Lösung dar, da es die hohe Genauigkeit der Prompt-Engineering-Lösung mit einer erheblich gesteigerten Effizienz kombiniert.
\texttt{Qwen2.5-1.5B-Instruct} zeigt mit seiner überlegenen Geschwindigkeit großes Potenzial.
Sollte es durch einen umfangreicheren Trainingsdatensatz und eine Optimierung der Trainingsparameter gelingen, dessen Extraktionsgenauigkeit zu steigern, könnte es sich als deutlich performantere Alternative etablieren.

\section{Ausblick und nächste Schritte}

Die initialen Experimente zeigen das Potenzial des Fine-Tunings.
Sie werfen jedoch auch Fragen auf, die in weiterführenden Untersuchungen adressiert werden sollten.
Die durchgeführten Tests beschränkten sich auf die Extraktion von einzelnen Copyright-Statements.
Komplexere Fälle sowie weitere Aspekte der Policy wurden noch nicht berücksichtigt.

Um die Policy vollständig abzubilden, ist die Erstellung eines umfangreichen, kuratierten Datensatzes erforderlich.
Dieser sollte insbesondere komplexe Konstellationen mit mehreren Copyright-Statements (\textit{multiple copyrights}) sowie gezielte False-Negative- und False-Positive-Fälle abdecken.
Ein solcher Datensatz würde es ermöglichen, das Modell auch auf die anspruchsvollsten Extraktionsfälle zu trainieren und die Generalisierungsfähigkeit zu verbessern.
Der im Kapitel~\ref{ch:daten} erzeugte Datensatz stellt zwar eine Grundlage dafür dar, bietet aber gerade in Hinsicht auf Blöcke von Copyright-Statements keine verlässliche Datenquelle ohne die Implementierung weiterer Mechanismen zur Validierung.

Eine systematische Untersuchung der Trainingsparameter und der Grenzen von Modellgrößen ist ein weiterer wichtiger Schritt.
Insbesondere die Optimierung kleinerer Modelle könnte es ermöglichen, eine hohe Extraktionsqualität bei gleichzeitig maximaler Geschwindigkeit zu erzielen.
Dies würde die Praxistauglichkeit der Lösung erheblich steigern.

\section{Potenzial und Nutzen des Fine-Tunings}

Der Ansatz, ein spezialisiertes Modell durch Fine-Tuning zu entwickeln, bietet gegenüber dem reinen Prompt-Engineering mehrere strategische Vorteile für den praktischen Einsatz.
Ein wesentlicher Vorteil liegt im impliziten Erlernen komplexer Regeln, da das Modell Anforderungen aus Tausenden von Beispielen verinnerlichen kann.
Dies ist besonders vorteilhaft für Regeln, deren explizite Formalisierung in einem Prompt zu umfangreich wäre oder die Grenzen des Few-Shot-Fensters überschreiten würde.
Ein weiterer Nutzen ist die vereinfachte Bereitstellung und Anwendung, da das Ergebnis des Fine-Tunings ein einzelnes, spezialisiertes Modell-File ist, das mit minimalem Setup in bestehende Prozesse integriert werden kann.
Damit geht auch eine hohe Effizienz und lokale Ausführbarkeit einher.
Wie die Experimente mit \texttt{qwen2.5-1.5b-instruct} andeuten, können auch sehr kleine Modelle spezialisiert werden, was den Einsatz auf Hardware mit begrenzten Ressourcen ermöglicht.
Zuletzt kann durch einen vielfältigen Trainingsdatensatz eine implizite Sprachunterstützung erreicht werden, sodass das Modell Copyright-Informationen in verschiedenen Sprachen korrekt extrahieren kann, ohne dass für jede Sprache ein eigener Prompt entwickelt werden muss.









