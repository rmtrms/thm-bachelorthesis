\chapter{Diskussion}\label{ch:diskussion}

Dieses Kapitel dient der Einordnung, Interpretation und kritischen Reflexion der in dieser Arbeit erzielten Ergebnisse.
Es werden die Resultate in den Kontext der ursprünglichen Problemstellung und der definierten Anforderungen gestellt.
Hierzu werden die Anwendungsszenarien (AS) aus~\ref{ch:anwendungsszenarien} sowie die funktionalen (F) und nicht-funktionalen (NF) Anforderungen herangezogen.
Darüber hinaus werden die Herausforderungen und Limitationen der Untersuchung beleuchtet und die Vorgehensweise im Hinblick auf Erfolge sowie Versäumnisse kritisch gewürdigt.

% ======================================================================================================================

\section{Interpretation der Ergebnisse im Kontext der ursprünglichen Problemstellung}

Die vorliegende Arbeit adressiert die methodischen Schwächen etablierter, regelbasierter Systeme bei der Extraktion von Copyright-Informationen und demonstriert, dass der entwickelte, auf \glspl{llm} basierende Ansatz eine leistungsfähige Alternative darstellt.
Die Auswahl des finalen Sprachmodells erfolgte nicht willkürlich, sondern basierte auf einem dokumentierten Evaluationsverfahren, das einen systematischen Vergleich mehrerer Kandidaten ermöglichte, womit das Modellauswahlverfahren nachvollziehbar begründet ist (NF7).
Durch gezieltes Prompt-Engineering konnte mit dem Modell \texttt{mistral-small:24b} eine Extraktionsgenauigkeit von \num{96,3} \% \textit{Exact Matches} erreicht werden.
Damit wurde die Anforderung einer Extraktionsgenauigkeit von mindestens \num{95} \% nicht nur erfüllt, sondern übertroffen (NF1).

Die gesamte Entwicklung wurde auf der dedizierten Hardware der metaeffekt GmbH durchgeführt, wodurch die Hardware-Kompatibilität sichergestellt werden konnte (NF8).
Sowohl die Software zur Datenaggregation als auch der Benchmark und der finale Scanner wurden vollständig in Java implementiert, was der geforderten Implementierungssprache entspricht (NF9).
Um die deterministische Natur der Ergebnisse zu gewährleisten, wurden feste Modellversionen mit einer Temperatur von \num{0.0} lokal ausgeführt, sodass die Reproduzierbarkeit der Extraktion gegeben ist (NF3).
Der Verarbeitungsprozess ist zudem durch die Speicherung aller relevanten Zwischenschritte von der Eingabe bis zur finalen Ausgabe für jede Datei vollständig nachvollziehbar (NF4).

Die Softwarelösung ist robust gegenüber technischen Fehlern konzipiert und protokolliert diese, ohne die gesamte Verarbeitungskette zu unterbrechen (NF2).
Um Blockaden durch nicht terminierende Anfragen zu verhindern, stellt ein Mechanismus zur Zeitüberschreitung sicher, dass jede Anfrage nach einem definierten Limit kontrolliert beendet wird (NF6).
Die erfolgreiche Erzeugung von \num{4000} Trainingsdateien in einem Durchlauf demonstrierte, dass die Lösung eine Batch-Verarbeitung von mehreren tausend Eingabedateien unterstützt (NF5).
Eine Datenvorverarbeitung reduziert die Eingabedateien auf relevante Abschnitte und spart somit Rechenressourcen (F4).
Die extrahierten Informationen werden in einem strukturierten und zum ScanCode-Toolkit kompatiblen JSON-Format ausgegeben (F1).
Die Modellantworten werden auf ein valides JSON-Format überprüft und bei Bedarf korrigiert, was die Ergebnisvalidierung sicherstellt (F2).
Sollte eine Antwort auch nach der Korrektur ungültig bleiben, wird dies als Fehlerfall dokumentiert und die Verarbeitung entsprechend fortgesetzt (F3).

Alle eingesetzten Modelle und Werkzeuge stehen unter der Apache-2.0-Lizenz, was eine lizenzkonforme Nutzung im kommerziellen Kontext erlaubt (NF10).
Die Kompatibilität des Ausgabeformats mit bestehenden Werkzeugen der metaeffekt GmbH schafft die Grundlage für eine nahtlose Systemintegration (NF11).
Die Prompt-Engineering-Lösung setzt alle als \enquote{in-scope} gekennzeichneten Regeln der Policy um und gewährleistet somit die erforderliche Policy-Abdeckung (F5).

Das erste Anwendungsszenario zur Generierung eines Testdatensatzes wurde weitgehend umgesetzt und der erstellte Datensatz kann als wertvolle Basis für zukünftige Arbeiten dienen, auch wenn eine automatische Validierung von Copyright-Blöcken noch aussteht (AS1).
Für die Anwendungsszenarien der internen und kundenseitigen Inbetriebnahme wurden entscheidende Grundlagen geschaffen (AS2, AS3).

% ======================================================================================================================

% TODO: Eventuell ergänzen, dass Prompt-Engineering Lösung im Rahmen des Benchmarks optimiert wurde anstatt mit einem ganzheitlichen Ansatz

\section{Herausforderungen und Limitationen bei der Umsetzung und Evaluierung}

Die Durchführung der Arbeit war mit verschiedenen Herausforderungen und Limitationen verbunden.
Die verwendete Hardware ermöglichte zwar die Ausführung größerer \glspl{llm}, brachte jedoch auch zeitliche Beschränkungen mit sich.
Insbesondere aufwendige Durchläufe wie der Benchmark oder das Fine-Tuning nahmen teilweise mehrere Stunden in Anspruch, was die Anzahl möglicher Iterationen und Experimente begrenzte.

Eine wesentliche Limitation der Arbeit liegt in der Erstellung des Evaluations- und Trainingsdatensatzes.
Aus zeitlichen und personellen Gründen konnte keine umfassende Annotation von Daten durch externe Experten erfolgen.
Die manuelle Pflege und Validierung der Datensätze basierte daher primär auf der Einschätzung des Autors, was eine potenzielle Subjektivität und Fehlerquelle darstellt.

% ======================================================================================================================

\section{Kritische Würdigung der Vorgehensweise in Hinsicht auf Erfolge und Versäumnisse}

Im Rückblick lassen sich einige Versäumnisse in der Vorgehensweise identifizieren.
Der durchgeführte Benchmark basierte auf einem Datensatz von lediglich \num{200} Dateien.
Für ein statistisch aussagekräftigeres und generalisierbareres Ergebnis wäre ein umfangreicherer Benchmarkdatensatz notwendig gewesen.
Auch die zur Vorverarbeitung der Eingabedateien genutzte Wortliste wurde manuell durch Beobachtung und iterative Verbesserung erstellt.
Eine zuverlässige Produktivlösung würde hier einen automatisierten Ansatz zur Generierung erfordern.
Ebenso erfolgte das Prompt-Engineering manuell, während ein automatisierter Prozess, der wirkungsvolle Beispiele und Instruktionsvarianten systematisch kombiniert, perspektivisch eine bessere Lösung darstellt.
Ein weiteres Defizit zeigt sich bei der Erzeugung von Testdaten für das Fine-Tuning, da hier ein expliziter Validierungsschritt fehlte und stattdessen nur die vorherige Analyse ungesehener Daten als Gütekriterium herangzeogen wurde.
Insbesondere bei komplexen Blöcken von Copyright-Statements, bei denen die optimierte Lösung unzureichende Ergebnisse erzielte, wäre eine anschließende Validierung notwendig gewesen um diesen Eingabetyp auch im Fine-Tuning zu unterstützen.
Schließlich wurde das Fine-Tuning nur durch initiale Experimente als Option analysiert, eine tiefgehende Untersuchung mit verschiedenen Trainingsparametern fand nicht statt.

Diesen Versäumnissen stehen jedoch bedeutende Erfolge gegenüber.
So gelang es trotz des engen zeitlichen Rahmens, eine vollständige \gls{llm}-Entwicklungspipeline von der Datenaggregation über den Benchmark und das Prompt-Engineering bis hin zum Fine-Tuning mittels Knowledge-Distillation erfolgreich zu konzipieren und durchzuführen.
Der Benchmark selbst erwies sich als aussagekräftig, da die weite Streuung der Ergebnisse seine grundsätzliche Lösbarkeit und Eignung zur Modelldifferenzierung belegte.
Das systematische Prompt-Engineering führte zu hohen Präzisionsergebnissen.
Auch die initialen Experimente zum Fine-Tuning waren erfolgreich, indem ein kleineres, spezialisiertes Modell eine vergleichbare Genauigkeit bei signifikant höherer Effizienz erreichte.
Schließlich stellt die im Rahmen der Arbeit weiter ausformulierte und verfeinerte Policy eine wertvolle Grundlage für die metaeffekt GmbH und ihre Kunden für zukünftige Arbeiten dar.
