
@article{breton_empowering_2024,
	title = {Empowering {CamemBERT} Legal Entity Extraction With {LLM} Boostrapping},
	doi = {10.1007/978-3-031-77792-9_6},
	abstract = {The legal industry is characterized by the presence of large volumes and complex documents. Given the continuous evolution of these documents, there is a growing interest in automating the processing of legal texts to streamline compliance. One key step of this process is the extraction of legal entities. State-of-the-art methods for legal entity extraction, including rule-based systems, Bi-{LSTM}, and {BERT}, require substantial annotated data to be effective, a task that is time-intensive for domain experts. With the rise of Large Language Models ({LLMs}), research has increasingly focused on leveraging their capabilities and exploring zero-shot approaches. In this paper, we present a hybrid system that distils {GPT}-4 knowledge through rule-based methods into a {CamemBERT} model. This approach not only reduces the need for expert involvement compared to the standard {CamemBERT} system but also outperforms the {GPT}-4-only system, enhancing the F1 score for legal entities by 9-24\% points.},
	pages = {86--101},
	journaltitle = {{EKAW} 2024},
	author = {Breton, Julien and Billami, Mokhtar Boumedyen and Chevalier, Max and Trojahn, Cassia},
	date = {2024-11-20},
	note = {Publisher: {CCSD}},
	keywords = {Large Language Models ({LLMs}), [{INFO}]Computer Science [cs], Amsterdam, Netherlands, Camem-{BERT}, Knowledge Distilation, Legal Entity Extraction, Limited Annotated Data},
	file = {Breton et al. - 2024 - Empowering CamemBERT Legal Entity Extraction With .pdf:/Users/romeo/Zotero/storage/NBTVDFRP/Breton et al. - 2024 - Empowering CamemBERT Legal Entity Extraction With .pdf:application/pdf},
}

@misc{pakhale_comprehensive_2023,
	title = {Comprehensive Overview of Named Entity Recognition: Models, Domain-Specific Applications and Challenges},
	url = {http://arxiv.org/abs/2309.14084},
	doi = {10.48550/arXiv.2309.14084},
	shorttitle = {Comprehensive Overview of Named Entity Recognition},
	abstract = {In the domain of Natural Language Processing ({NLP}), Named Entity Recognition ({NER}) stands out as a pivotal mechanism for extracting structured insights from unstructured text. This manuscript offers an exhaustive exploration into the evolving landscape of {NER} methodologies, blending foundational principles with contemporary {AI} advancements. Beginning with the rudimentary concepts of {NER}, the study spans a spectrum of techniques from traditional rule-based strategies to the contemporary marvels of transformer architectures, particularly highlighting integrations such as {BERT} with {LSTM} and {CNN}. The narrative accentuates domain-specific {NER} models, tailored for intricate areas like finance, legal, and healthcare, emphasizing their specialized adaptability. Additionally, the research delves into cutting-edge paradigms including reinforcement learning, innovative constructs like E-{NER}, and the interplay of Optical Character Recognition ({OCR}) in augmenting {NER} capabilities. Grounding its insights in practical realms, the paper sheds light on the indispensable role of {NER} in sectors like finance and biomedicine, addressing the unique challenges they present. The conclusion outlines open challenges and avenues, marking this work as a comprehensive guide for those delving into {NER} research and applications.},
	number = {{arXiv}:2309.14084},
	publisher = {{arXiv}},
	author = {Pakhale, Kalyani},
	urldate = {2025-06-04},
	date = {2023-09-25},
	eprinttype = {arxiv},
	eprint = {2309.14084 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {Preprint PDF:/Users/romeo/Zotero/storage/4GPFMSPY/Pakhale - 2023 - Comprehensive Overview of Named Entity Recognition.pdf:application/pdf;Snapshot:/Users/romeo/Zotero/storage/TERZWKDY/2309.html:text/html},
}

@misc{dunn_structured_2022,
	title = {Structured information extraction from complex scientific text with fine-tuned large language models},
	url = {http://arxiv.org/abs/2212.05238},
	doi = {10.48550/arXiv.2212.05238},
	abstract = {Intelligently extracting and linking complex scientific information from unstructured text is a challenging endeavor particularly for those inexperienced with natural language processing. Here, we present a simple sequence-to-sequence approach to joint named entity recognition and relation extraction for complex hierarchical information in scientific text. The approach leverages a pre-trained large language model ({LLM}), {GPT}-3, that is fine-tuned on approximately 500 pairs of prompts (inputs) and completions (outputs). Information is extracted either from single sentences or across sentences in abstracts/passages, and the output can be returned as simple English sentences or a more structured format, such as a list of {JSON} objects. We demonstrate that {LLMs} trained in this way are capable of accurately extracting useful records of complex scientific knowledge for three representative tasks in materials chemistry: linking dopants with their host materials, cataloging metal-organic frameworks, and general chemistry/phase/morphology/application information extraction. This approach represents a simple, accessible, and highly-flexible route to obtaining large databases of structured knowledge extracted from unstructured text. An online demo is available at http://www.matscholar.com/info-extraction.},
	number = {{arXiv}:2212.05238},
	publisher = {{arXiv}},
	author = {Dunn, Alexander and Dagdelen, John and Walker, Nicholas and Lee, Sanghoon and Rosen, Andrew S. and Ceder, Gerbrand and Persson, Kristin and Jain, Anubhav},
	urldate = {2025-06-05},
	date = {2022-12-10},
	eprinttype = {arxiv},
	eprint = {2212.05238 [cs]},
	keywords = {Computer Science - Computation and Language, Condensed Matter - Materials Science},
	file = {Preprint PDF:/Users/romeo/Zotero/storage/KUCKDM2F/Dunn et al. - 2022 - Structured information extraction from complex sci.pdf:application/pdf;Snapshot:/Users/romeo/Zotero/storage/CXQBSCLJ/2212.html:text/html},
}

@misc{wei_chatie_2024,
	title = {{ChatIE}: Zero-Shot Information Extraction via Chatting with {ChatGPT}},
	url = {http://arxiv.org/abs/2302.10205},
	doi = {10.48550/arXiv.2302.10205},
	shorttitle = {{ChatIE}},
	abstract = {Zero-shot information extraction ({IE}) aims to build {IE} systems from the unannotated text. It is challenging due to involving little human intervention. Challenging but worthwhile, zero-shot {IE} reduces the time and effort that data labeling takes. Recent efforts on large language models ({LLMs}, e.g., {GPT}-3, {ChatGPT}) show promising performance on zero-shot settings, thus inspiring us to explore prompt-based methods. In this work, we ask whether strong {IE} models can be constructed by directly prompting {LLMs}. Specifically, we transform the zero-shot {IE} task into a multi-turn question-answering problem with a two-stage framework ({ChatIE}). With the power of {ChatGPT}, we extensively evaluate our framework on three {IE} tasks: entity-relation triple extract, named entity recognition, and event extraction. Empirical results on six datasets across two languages show that {ChatIE} achieves impressive performance and even surpasses some full-shot models on several datasets (e.g., {NYT}11-{HRL}). We believe that our work could shed light on building {IE} models with limited resources.},
	number = {{arXiv}:2302.10205},
	publisher = {{arXiv}},
	author = {Wei, Xiang and Cui, Xingyu and Cheng, Ning and Wang, Xiaobin and Zhang, Xin and Huang, Shen and Xie, Pengjun and Xu, Jinan and Chen, Yufeng and Zhang, Meishan and Jiang, Yong and Han, Wenjuan},
	urldate = {2025-06-05},
	date = {2024-05-27},
	eprinttype = {arxiv},
	eprint = {2302.10205 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/romeo/Zotero/storage/5YXWZLP5/Wei et al. - 2024 - ChatIE Zero-Shot Information Extraction via Chatt.pdf:application/pdf;Snapshot:/Users/romeo/Zotero/storage/EHGH3CR3/2302.html:text/html},
}

@misc{islam_llm-based_2025,
	title = {{LLM}-based Prompt Ensemble for Reliable Medical Entity Recognition from {EHRs}},
	url = {http://arxiv.org/abs/2505.08704},
	doi = {10.48550/arXiv.2505.08704},
	abstract = {Electronic Health Records ({EHRs}) are digital records of patient information, often containing unstructured clinical text. Named Entity Recognition ({NER}) is essential in {EHRs} for extracting key medical entities like problems, tests, and treatments to support downstream clinical applications. This paper explores prompt-based medical entity recognition using large language models ({LLMs}), specifically {GPT}-4o and {DeepSeek}-R1, guided by various prompt engineering techniques, including zero-shot, few-shot, and an ensemble approach. Among all strategies, {GPT}-4o with prompt ensemble achieved the highest classification performance with an F1-score of 0.95 and recall of 0.98, outperforming {DeepSeek}-R1 on the task. The ensemble method improved reliability by aggregating outputs through embedding-based similarity and majority voting.},
	number = {{arXiv}:2505.08704},
	publisher = {{arXiv}},
	author = {Islam, K. M. Sajjadul and Nipu, Ayesha Siddika and Wu, Jiawei and Madiraju, Praveen},
	urldate = {2025-06-14},
	date = {2025-05-25},
	eprinttype = {arxiv},
	eprint = {2505.08704 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/romeo/Zotero/storage/ENSALNXQ/Islam et al. - 2025 - LLM-based Prompt Ensemble for Reliable Medical Ent.pdf:application/pdf;Snapshot:/Users/romeo/Zotero/storage/4HM5SYIL/2505.html:text/html},
}

@misc{villena_llmner_2024,
	title = {{llmNER}: (Zero{\textbar}Few)-Shot Named Entity Recognition, Exploiting the Power of Large Language Models},
	url = {http://arxiv.org/abs/2406.04528},
	doi = {10.48550/arXiv.2406.04528},
	shorttitle = {{llmNER}},
	abstract = {Large language models ({LLMs}) allow us to generate high-quality human-like text. One interesting task in natural language processing ({NLP}) is named entity recognition ({NER}), which seeks to detect mentions of relevant information in documents. This paper presents {llmNER}, a Python library for implementing zero-shot and few-shot {NER} with {LLMs}; by providing an easy-to-use interface, {llmNER} can compose prompts, query the model, and parse the completion returned by the {LLM}. Also, the library enables the user to perform prompt engineering efficiently by providing a simple interface to test multiple variables. We validated our software on two {NER} tasks to show the library's flexibility. {llmNER} aims to push the boundaries of in-context learning research by removing the barrier of the prompting and parsing steps.},
	number = {{arXiv}:2406.04528},
	publisher = {{arXiv}},
	author = {Villena, Fabián and Miranda, Luis and Aracena, Claudio},
	urldate = {2025-06-14},
	date = {2024-06-06},
	eprinttype = {arxiv},
	eprint = {2406.04528 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/romeo/Zotero/storage/VM28DBAB/Villena et al. - 2024 - llmNER (ZeroFew)-Shot Named Entity Recognition, .pdf:application/pdf;Snapshot:/Users/romeo/Zotero/storage/EJYPISAY/2406.html:text/html},
}

@misc{hu_improving_2024,
	title = {Improving Large Language Models for Clinical Named Entity Recognition via Prompt Engineering},
	url = {http://arxiv.org/abs/2303.16416},
	doi = {10.48550/arXiv.2303.16416},
	abstract = {Objective: This study quantifies the capabilities of {GPT}-3.5 and {GPT}-4 for clinical named entity recognition ({NER}) tasks and proposes task-specific prompts to improve their performance. Materials and Methods: We evaluated these models on two clinical {NER} tasks: (1) to extract medical problems, treatments, and tests from clinical notes in the {MTSamples} corpus, following the 2010 i2b2 concept extraction shared task, and (2) identifying nervous system disorder-related adverse events from safety reports in the vaccine adverse event reporting system ({VAERS}). To improve the {GPT} models' performance, we developed a clinical task-specific prompt framework that includes (1) baseline prompts with task description and format specification, (2) annotation guideline-based prompts, (3) error analysis-based instructions, and (4) annotated samples for few-shot learning. We assessed each prompt's effectiveness and compared the models to {BioClinicalBERT}. Results: Using baseline prompts, {GPT}-3.5 and {GPT}-4 achieved relaxed F1 scores of 0.634, 0.804 for {MTSamples}, and 0.301, 0.593 for {VAERS}. Additional prompt components consistently improved model performance. When all four components were used, {GPT}-3.5 and {GPT}-4 achieved relaxed F1 socres of 0.794, 0.861 for {MTSamples} and 0.676, 0.736 for {VAERS}, demonstrating the effectiveness of our prompt framework. Although these results trail {BioClinicalBERT} (F1 of 0.901 for the {MTSamples} dataset and 0.802 for the {VAERS}), it is very promising considering few training samples are needed. Conclusion: While direct application of {GPT} models to clinical {NER} tasks falls short of optimal performance, our task-specific prompt framework, incorporating medical knowledge and training samples, significantly enhances {GPT} models' feasibility for potential clinical applications.},
	number = {{arXiv}:2303.16416},
	publisher = {{arXiv}},
	author = {Hu, Yan and Chen, Qingyu and Du, Jingcheng and Peng, Xueqing and Keloth, Vipina Kuttichi and Zuo, Xu and Zhou, Yujia and Li, Zehan and Jiang, Xiaoqian and Lu, Zhiyong and Roberts, Kirk and Xu, Hua},
	urldate = {2025-06-14},
	date = {2024-01-25},
	eprinttype = {arxiv},
	eprint = {2303.16416 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/romeo/Zotero/storage/ESY5GXM2/Hu et al. - 2024 - Improving Large Language Models for Clinical Named.pdf:application/pdf;Snapshot:/Users/romeo/Zotero/storage/CJBNURAR/2303.html:text/html},
}

@online{noauthor_chatutil-yan-wittmann_nodate,
	title = {{ChatUtil}-Yan-Wittmann},
	url = {https://github.com/YanWittmann/automatic-document-classification/blob/main/src/main/java/de/yanwittmann/document/ai/ChatUtil.java},
	abstract = {{OCR}/{AI}-powered automated document renaming and sorting - {YanWittmann}/automatic-document-classification},
	titleaddon = {{GitHub}},
	urldate = {2025-07-06},
	langid = {english},
}

@inreference{noauthor_f-score_2025,
	title = {F-score},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=F-score&oldid=1296408310},
	booktitle = {Wikipedia},
	urldate = {2025-07-06},
	date = {2025-06-19},
	langid = {english},
	note = {Page Version {ID}: 1296408310},
}

@online{noauthor_what_nodate,
	title = {What are tokens and how to count them? {\textbar} {OpenAI} Help Center},
	url = {https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them},
	shorttitle = {What are tokens and how to count them?},
	urldate = {2025-07-06},
	langid = {english},
}

@online{noauthor_scancode-toolkit-documentation_nodate,
	title = {{ScanCode}-Toolkit-Documentation},
	url = {https://scancode-toolkit.readthedocs.io/en/latest/getting-started/home.html},
	urldate = {2025-07-06},
	file = {Home — ScanCode-Toolkit documentation:/Users/romeo/Zotero/storage/TXFK69CE/home.html:text/html},
}

@online{noauthor_ollama_nodate,
	title = {Ollama},
	url = {https://ollama.com},
	abstract = {Get up and running with large language models.},
	urldate = {2025-07-06},
	file = {Snapshot:/Users/romeo/Zotero/storage/CEGHQQ3F/ollama.com.html:text/html},
}

@software{noauthor_metaeffekt-scancode-service_2025,
	title = {Metaeffekt-{ScanCode}-Service},
	rights = {Apache-2.0},
	url = {https://github.com/org-metaeffekt/metaeffekt-scancode-service},
	abstract = {Local service for efficient integration of {ScanCode} Toolkit.},
	publisher = {\{metæffekt\}},
	urldate = {2025-07-06},
	date = {2025-05-14},
	note = {original-date: 2024-03-20T12:57:22Z},
	keywords = {scancode},
}

@unpublished{gang_smarter_2025,
	title = {Smarter Fine-Tuning: How {LoRA} Enhances Large Language Models},
	url = {https://hal.science/hal-04983079},
	shorttitle = {Smarter Fine-Tuning},
	abstract = {The rapid advancement of Large Language Models ({LLMs}) has revolutionized natural language processing ({NLP}) and various {AI}-driven applications. However, the fine-tuning of such massive models remains computationally expensive, limiting their adaptability to domain-specific tasks. Low-Rank Adaptation ({LoRA}) has emerged as a prominent parameter-efficient fine-tuning ({PEFT}) technique that significantly reduces memory and computational overhead by introducing trainable low-rank matrices while freezing most of the pre-trained model parameters. {LoRA} enables efficient model adaptation without compromising performance, making it an attractive alternative to full fine-tuning. This survey provides a comprehensive overview of {LoRA}, including its theoretical foundations, integration into transformer-based architectures, and comparative advantages over traditional fine-tuning techniques. We explore its applications across diverse domains, including {NLP}, code generation, healthcare, finance, and multimodal {AI}. Additionally, we examine real-world case studies that demonstrate {LoRA}'s effectiveness in optimizing computational costs while preserving model performance. Despite its numerous benefits, {LoRA} presents several challenges, including optimal rank selection, generalization across multiple tasks, and its dependency on pre-trained model capabilities. We discuss these limitations and highlight promising future research directions, such as adaptive rank estimation, multimodal extensions, federated learning integration, and energy-efficient variants. By bridging the gap between efficiency and adaptability, {LoRA} represents a pivotal advancement in democratizing {LLM} fine-tuning. As {AI} models continue to scale, {LoRA} will play an essential role in enabling cost-effective and scalable adaptation, driving innovation in {AI} applications across industries.},
	author = {Gang, Yue and Shun, Jianhong and Qing, Mu},
	urldate = {2025-07-20},
	date = {2025-03},
	keywords = {Deep Learning, Large Language Models, {AI} Optimization, Computational Efficiency, Low-Rank Adaptation, Model Adaptation, {NLP}, Parameter-Efficient Fine-Tuning, Transfer Learning, Transformer Models},
	file = {HAL PDF Full Text:/Users/romeo/Zotero/storage/C3E4NUVX/Gang et al. - 2025 - Smarter Fine-Tuning How LoRA Enhances Large Langu.pdf:application/pdf},
}

@article{benlahbib_comparative_2025,
	title = {Comparative Analysis of Traditional and Modern {NLP} Techniques on the {CoLA} Dataset: From {POS} Tagging to Large Language Models},
	volume = {6},
	issn = {2644-1268},
	url = {https://ieeexplore.ieee.org/document/10829978},
	doi = {10.1109/OJCS.2025.3526712},
	shorttitle = {Comparative Analysis of Traditional and Modern {NLP} Techniques on the {CoLA} Dataset},
	abstract = {The task of classifying linguistic acceptability, exemplified by the {CoLA} (Corpus of Linguistic Acceptability) dataset, poses unique challenges for natural language processing ({NLP}) models. These challenges include distinguishing between subtle grammatical errors, understanding complex syntactic structures, and detecting semantic inconsistencies, all of which make the task difficult even for human annotators. In this article, we compare a range of techniques, from traditional methods such as Part-of-Speech ({POS}) tagging and feature extraction methods like {CountVectorizer} with Term Frequency-Inverse Document Frequency ({TF}-{IDF}) and N-grams, to modern embeddings such as {FastText} and Embeddings from Language Models ({ELMo}), as well as deep learning architectures like transformers and Large Language Models ({LLMs}). Our experiments show a clear improvement in performance as models evolve from traditional to more advanced approaches. Notably, state-of-the-art ({SOTA}) results were obtained by fine-tuning {GPT}-4o with extensive hyperparameter tuning, including experimenting with various epochs and batch sizes. This comparative analysis provides valuable insights into the relative strengths of each technique for identifying morphological, syntactic, and semantic violations, highlighting the effectiveness of {LLMs} in these tasks.},
	pages = {248--260},
	journaltitle = {{IEEE} Open Journal of the Computer Society},
	author = {Benlahbib, Abdessamad and Boumhidi, Achraf and Fahfouh, Anass and Alami, Hamza},
	urldate = {2025-07-20},
	date = {2025},
	keywords = {Data models, natural language processing, Benchmark testing, Computational modeling, Correlation coefficient, Large language models, Large language models ({LLMs}), linguistic acceptability, Linguistics, Natural language processing, Syntactics, Tagging, Transformers},
	file = {Full Text PDF:/Users/romeo/Zotero/storage/JZW9VQJZ/Benlahbib et al. - 2025 - Comparative Analysis of Traditional and Modern NLP.pdf:application/pdf},
}

@article{siino_exploring_2025,
	title = {Exploring {LLMs} Applications in Law: A Literature Review on Current Legal {NLP} Approaches},
	volume = {13},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10850911},
	doi = {10.1109/ACCESS.2025.3533217},
	shorttitle = {Exploring {LLMs} Applications in Law},
	abstract = {Artificial Intelligence ({AI}) is reshaping the legal landscape, with software tools now impacting various aspects of legal work. The intersection of Natural Language Processing ({NLP}) and law holds potential to transform how legal professionals, including lawyers and judges, operate, resolve disputes, and retrieve case information to formulate their decisions. To identify the current state of the applications of Transformers (also known as Large Language Models or {LLMs}) in the legal domain, we analysed the existing literature from 2017 to 2023 through a database search and snowballing method. From 61 selected publications, we identified key application categories such as legal document analysis, case prediction, and contract review, along with their main characteristics. We observed a discernible upsurge in the volume of scholarly publications, a diversification of tasks undertaken (e.g., legal research, contract analysis, and regulatory compliance), and an increased range of languages considered. There has been a notable enhancement in the methodological sophistication employed by researchers in practical applications. The performance of models grounded in the Generative Pre-trained Transformer ({GPT}) architecture has consistently improved across various legal domains, including contract review, legal document summarization, and case outcome prediction. This paper makes several significant contributions to the field. Firstly, it identifies emerging trends in the application of {LLMs} within the legal domain, highlighting the growing interest and investment in this area. Secondly, it pinpoints methodological gaps in current research, suggesting areas where further development and refinement are needed. Lastly, it discusses the broader implications of these advancements for real-world legal tasks, offering insights into how {LLM}-based {AI} can enhance legal practice while addressing the associated challenges.},
	pages = {18253--18276},
	journaltitle = {{IEEE} Access},
	author = {Siino, Marco and Falco, Mariana and Croce, Daniele and Rosso, Paolo},
	urldate = {2025-07-20},
	date = {2025},
	keywords = {{GPT}, Artificial intelligence, Natural language processing, Transformers, {AI} for law, Attention mechanisms, Contracts, Databases, law, Law, legal {NLP}, legal tech, literature review, Quality assessment, Question answering (information retrieval), Reliability, Systematic literature review, transformers},
	file = {Full Text PDF:/Users/romeo/Zotero/storage/J8IGWHI2/Siino et al. - 2025 - Exploring LLMs Applications in Law A Literature R.pdf:application/pdf},
}

@article{noauthor_open-source-leitfaden_nodate,
	title = {Open-Source-Leitfaden},
	langid = {german},
	file = {Bitkom, Open Source Leitfaden, Version 3.2:/Users/romeo/Zotero/storage/5I9AP2C8/Open-Source-Leitfaden.pdf:application/pdf},
}

@online{meckel_definition_nodate,
	title = {Definition: Welt-Urheberrechts-Abkommen},
	url = {https://wirtschaftslexikon.gabler.de/definition/welt-urheberrechts-abkommen-50140},
	shorttitle = {Definition},
	abstract = {Universal Copyright Convention. Am 6.9.1952 unterzeichnetes, am 24.7.1971 revidiertes, aufgrund Vertragsgesetz vom 17.8.1973 ({BGBl}. {II} 1069) in der Bundesrepublik Deutschland am 10.7.1974 in Kraft getretenes ({BGBl}. {II} 1309) Abkommen, das den Werken fremder Autoren den gleichen Schutz gewähren soll},
	titleaddon = {https://wirtschaftslexikon.gabler.de/definition/welt-urheberrechts-abkommen-50140},
	type = {Text},
	author = {Meckel, Dr Astrid},
	urldate = {2025-07-24},
	langid = {german},
	note = {Publisher: Springer Fachmedien Wiesbaden {GmbH}
Section: economy},
}

@online{meckel_definition_nodate-1,
	title = {Definition: Revidierte Berner Übereinkunft ({RBÜ})},
	url = {https://wirtschaftslexikon.gabler.de/definition/revidierte-berner-uebereinkunft-rbue-42397},
	shorttitle = {Definition},
	abstract = {völkerrechtlicher Vertrag zum Schutz von Werken der Literatur und Kunst vom 9.9.1886 mit Änderungen von Paris (1896), Berlin (1908), Bern (1914), Rom (1928), Brüssel (1948), Stockholm (1967) und Paris (1971, {BGBl}. 1973 {II} 1071). Die Verwaltungsaufgaben des Verbands werden vom internationalen},
	titleaddon = {https://wirtschaftslexikon.gabler.de/definition/revidierte-berner-uebereinkunft-rbue-42397},
	type = {Text},
	author = {Meckel, Dr Astrid},
	urldate = {2025-07-24},
	langid = {german},
	note = {Publisher: Springer Fachmedien Wiesbaden {GmbH}
Section: economy},
}

@online{noauthor_jarowinkler_nodate,
	title = {Jaro–Winkler distance - Wikipedia},
	url = {https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance},
	urldate = {2025-07-24},
	file = {ED325505.pdf:/Users/romeo/Zotero/storage/HSGQG8ZW/Jaro–Winkler_distance.html:text/html},
}

@misc{mancera_pba-llm_2025,
	title = {{PBa}-{LLM}: Privacy- and Bias-aware {NLP} using Named-Entity Recognition ({NER})},
	url = {http://arxiv.org/abs/2507.02966},
	doi = {10.48550/arXiv.2507.02966},
	shorttitle = {{PBa}-{LLM}},
	abstract = {The use of Natural Language Processing ({NLP}) in highstakes {AI}-based applications has increased significantly in recent years, especially since the emergence of Large Language Models ({LLMs}). However, despite their strong performance, {LLMs} introduce important legal/ ethical concerns, particularly regarding privacy, data protection, and transparency. Due to these concerns, this work explores the use of Named- Entity Recognition ({NER}) to facilitate the privacy-preserving training (or adaptation) of {LLMs}. We propose a framework that uses {NER} technologies to anonymize sensitive information in text data, such as personal identities or geographic locations. An evaluation of the proposed privacy-preserving learning framework was conducted to measure its impact on user privacy and system performance in a particular high-stakes and sensitive setup: {AI}-based resume scoring for recruitment processes. The study involved two language models ({BERT} and {RoBERTa}) and six anonymization algorithms (based on Presidio, {FLAIR}, {BERT}, and different versions of {GPT}) applied to a database of 24,000 candidate profiles. The findings indicate that the proposed privacy preservation techniques effectively maintain system performance while playing a critical role in safeguarding candidate confidentiality, thus promoting trust in the experimented scenario. On top of the proposed privacy-preserving approach, we also experiment applying an existing approach that reduces the gender bias in {LLMs}, thus finally obtaining our proposed Privacyand Bias-aware {LLMs} ({PBa}-{LLMs}). Note that the proposed {PBa}-{LLMs} have been evaluated in a particular setup (resume scoring), but are generally applicable to any other {LLM}-based {AI} application.},
	number = {{arXiv}:2507.02966},
	publisher = {{arXiv}},
	author = {Mancera, Gonzalo and Morales, Aythami and Fierrez, Julian and Tolosana, Ruben and Penna, Alejandro and Lopez-Duran, Miguel and Jurado, Francisco and Ortigosa, Alvaro},
	urldate = {2025-07-28},
	date = {2025-07-09},
	eprinttype = {arxiv},
	eprint = {2507.02966 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Cryptography and Security, Computer Science - Machine Learning},
	file = {Preprint PDF:/Users/romeo/Zotero/storage/JQ9STSQS/Mancera et al. - 2025 - PBa-LLM Privacy- and Bias-aware NLP using Named-E.pdf:application/pdf;Snapshot:/Users/romeo/Zotero/storage/UFFYEP8T/2507.html:text/html},
}

@misc{obeidat_llms_2025,
	title = {Do {LLMs} Surpass Encoders for Biomedical {NER}?},
	url = {http://arxiv.org/abs/2504.00664},
	doi = {10.48550/arXiv.2504.00664},
	abstract = {Recognizing spans of biomedical concepts and their types (e.g., drug or gene) in free text, often called biomedical named entity recognition ({NER}), is a basic component of information extraction ({IE}) pipelines. Without a strong {NER} component, other applications, such as knowledge discovery and information retrieval, are not practical. State-of-the-art in {NER} shifted from traditional {ML} models to deep neural networks with transformer-based encoder models (e.g., {BERT}) emerging as the current standard. However, decoder models (also called large language models or {LLMs}) are gaining traction in {IE}. But {LLM}-driven {NER} often ignores positional information due to the generative nature of decoder models. Furthermore, they are computationally very expensive (both in inference time and hardware needs). Hence, it is worth exploring if they actually excel at biomedical {NER} and assess any associated trade-offs (performance vs efficiency). This is exactly what we do in this effort employing the same {BIO} entity tagging scheme (that retains positional information) using five different datasets with varying proportions of longer entities. Our results show that the {LLMs} chosen (Mistral and Llama: 8B range) often outperform best encoder models ({BERT}-(un)cased, {BiomedBERT}, and {DeBERTav}3: 300M range) by 2-8\% in F-scores except for one dataset, where they equal encoder performance. This gain is more prominent among longer entities of length {\textgreater}= 3 tokens. However, {LLMs} are one to two orders of magnitude more expensive at inference time and may need cost prohibitive hardware. Thus, when performance differences are small or real time user feedback is needed, encoder models might still be more suitable than {LLMs}.},
	number = {{arXiv}:2504.00664},
	publisher = {{arXiv}},
	author = {Obeidat, Motasem S. and Nahian, Md Sultan Al and Kavuluru, Ramakanth},
	urldate = {2025-07-28},
	date = {2025-04-01},
	eprinttype = {arxiv},
	eprint = {2504.00664 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/romeo/Zotero/storage/R4KPLMJC/Obeidat et al. - 2025 - Do LLMs Surpass Encoders for Biomedical NER.pdf:application/pdf;Snapshot:/Users/romeo/Zotero/storage/FHJ3AHRM/2504.html:text/html},
}

@article{cheng_novel_2024,
	title = {A novel prompting method for few-shot {NER} via {LLMs}},
	volume = {8},
	issn = {2949-7191},
	url = {https://www.sciencedirect.com/science/article/pii/S2949719124000475},
	doi = {10.1016/j.nlp.2024.100099},
	abstract = {In various natural language processing tasks, significant strides have been made by Large Language Models ({LLMs}). Researchers leverage prompt method to conduct {LLMs} in accomplishing specific tasks under few-shot conditions. However, the prevalent use of {LLMs}’ prompt methods mainly focuses on guiding generative tasks, and employing existing prompts may result in poor performance in Named Entity Recognition ({NER}) tasks. To tackle this challenge, we propose a novel prompting method for few-shot {NER}. By enhancing existing prompt methods, we devise a standardized prompts tailored for the utilization of {LLMs} in {NER} tasks. Specifically, we structure the prompts into three components: task definition, few-shot demonstration, and output format. The task definition conducts {LLMs} in performing {NER} tasks, few-shot demonstration assists {LLMs} in understanding {NER} task objectives through specific output demonstration, and output format restricts {LLMs}’ output to prevent the generation of unnecessary results. The content of these components has been specifically tailored for {NER} tasks. Moreover, for the few-shot demonstration within the prompts, we propose a selection strategy that utilizes feedback from {LLMs}’ outputs to identify more suitable few-shot demonstration as prompts. Additionally, to enhance entity recognition performance, we enrich the prompts by summarizing error examples from the output process of {LLMs} and integrating them as additional prompts.},
	pages = {100099},
	journaltitle = {Natural Language Processing Journal},
	shortjournal = {Natural Language Processing Journal},
	author = {Cheng, Qi and Chen, Liqiong and Hu, Zhixing and Tang, Juan and Xu, Qiang and Ning, Binbin},
	urldate = {2025-07-28},
	date = {2024-09-01},
	keywords = {Deep learning, Large language model, Named entity recognition, Natural language processing, Prompt method},
	file = {Cheng et al. - 2024 - A novel prompting method for few-shot NER via LLMs.pdf:/Users/romeo/Zotero/storage/JERKQAS3/Cheng et al. - 2024 - A novel prompting method for few-shot NER via LLMs.pdf:application/pdf;ScienceDirect Snapshot:/Users/romeo/Zotero/storage/MM3JY4DN/S2949719124000475.html:text/html},
}

@inbook{malbon_standards_2014,
	title = {{STANDARDS} {CONCERNING} {THE} {AVAILABILITY}, {SCOPE} {AND} {USE} {OF} {INTELLECTUAL} {PROPERTY} {RIGHTS}},
	isbn = {978-1-78100-604-7},
	url = {http://www.elgaronline.com/view/9781845424435.00026.xml},
	pages = {239--240},
	booktitle = {The {WTO} Agreement on Trade-Related Aspects of Intellectual Property Rights},
	publisher = {Edward Elgar Publishing},
	bookauthor = {Malbon, Justin and Lawson, Charles and Davison, Mark},
	urldate = {2025-08-01},
	date = {2014},
	langid = {english},
	doi = {10.4337/9781781006047.00026},
	file = {2014 - STANDARDS CONCERNING THE AVAILABILITY, SCOPE AND U.pdf:/Users/romeo/Zotero/storage/RPS2R5XT/2014 - STANDARDS CONCERNING THE AVAILABILITY, SCOPE AND U.pdf:application/pdf},
}
