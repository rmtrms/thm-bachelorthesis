
@article{breton_empowering_2024,
	title = {Empowering {CamemBERT} {Legal} {Entity} {Extraction} {With} {LLM} {Boostrapping}},
	doi = {10.1007/978-3-031-77792-9_6},
	abstract = {The legal industry is characterized by the presence of large volumes and complex documents. Given the continuous evolution of these documents, there is a growing interest in automating the processing of legal texts to streamline compliance. One key step of this process is the extraction of legal entities. State-of-the-art methods for legal entity extraction, including rule-based systems, Bi-LSTM, and BERT, require substantial annotated data to be effective, a task that is time-intensive for domain experts. With the rise of Large Language Models (LLMs), research has increasingly focused on leveraging their capabilities and exploring zero-shot approaches. In this paper, we present a hybrid system that distils GPT-4 knowledge through rule-based methods into a CamemBERT model. This approach not only reduces the need for expert involvement compared to the standard CamemBERT system but also outperforms the GPT-4-only system, enhancing the F1 score for legal entities by 9-24\% points.},
	language = {English},
	journal = {EKAW 2024},
	author = {Breton, Julien and Billami, Mokhtar Boumedyen and Chevalier, Max and Trojahn, Cassia},
	month = nov,
	year = {2024},
	note = {Publisher: CCSD},
	keywords = {Large Language Models (LLMs), [INFO]Computer Science [cs], Amsterdam, Netherlands, Camem-BERT, Knowledge Distilation, Legal Entity Extraction, Limited Annotated Data},
	pages = {86--101},
	file = {Breton et al. - 2024 - Empowering CamemBERT Legal Entity Extraction With .pdf:/Users/romeo/Zotero/storage/NBTVDFRP/Breton et al. - 2024 - Empowering CamemBERT Legal Entity Extraction With .pdf:application/pdf},
}

@misc{pakhale_comprehensive_2023,
	title = {Comprehensive {Overview} of {Named} {Entity} {Recognition}: {Models}, {Domain}-{Specific} {Applications} and {Challenges}},
	shorttitle = {Comprehensive {Overview} of {Named} {Entity} {Recognition}},
	url = {http://arxiv.org/abs/2309.14084},
	doi = {10.48550/arXiv.2309.14084},
	abstract = {In the domain of Natural Language Processing (NLP), Named Entity Recognition (NER) stands out as a pivotal mechanism for extracting structured insights from unstructured text. This manuscript offers an exhaustive exploration into the evolving landscape of NER methodologies, blending foundational principles with contemporary AI advancements. Beginning with the rudimentary concepts of NER, the study spans a spectrum of techniques from traditional rule-based strategies to the contemporary marvels of transformer architectures, particularly highlighting integrations such as BERT with LSTM and CNN. The narrative accentuates domain-specific NER models, tailored for intricate areas like finance, legal, and healthcare, emphasizing their specialized adaptability. Additionally, the research delves into cutting-edge paradigms including reinforcement learning, innovative constructs like E-NER, and the interplay of Optical Character Recognition (OCR) in augmenting NER capabilities. Grounding its insights in practical realms, the paper sheds light on the indispensable role of NER in sectors like finance and biomedicine, addressing the unique challenges they present. The conclusion outlines open challenges and avenues, marking this work as a comprehensive guide for those delving into NER research and applications.},
	urldate = {2025-06-04},
	publisher = {arXiv},
	author = {Pakhale, Kalyani},
	month = sep,
	year = {2023},
	note = {arXiv:2309.14084 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {Preprint PDF:/Users/romeo/Zotero/storage/4GPFMSPY/Pakhale - 2023 - Comprehensive Overview of Named Entity Recognition.pdf:application/pdf;Snapshot:/Users/romeo/Zotero/storage/TERZWKDY/2309.html:text/html},
}

@misc{dunn_structured_2022,
	title = {Structured information extraction from complex scientific text with fine-tuned large language models},
	url = {http://arxiv.org/abs/2212.05238},
	doi = {10.48550/arXiv.2212.05238},
	abstract = {Intelligently extracting and linking complex scientific information from unstructured text is a challenging endeavor particularly for those inexperienced with natural language processing. Here, we present a simple sequence-to-sequence approach to joint named entity recognition and relation extraction for complex hierarchical information in scientific text. The approach leverages a pre-trained large language model (LLM), GPT-3, that is fine-tuned on approximately 500 pairs of prompts (inputs) and completions (outputs). Information is extracted either from single sentences or across sentences in abstracts/passages, and the output can be returned as simple English sentences or a more structured format, such as a list of JSON objects. We demonstrate that LLMs trained in this way are capable of accurately extracting useful records of complex scientific knowledge for three representative tasks in materials chemistry: linking dopants with their host materials, cataloging metal-organic frameworks, and general chemistry/phase/morphology/application information extraction. This approach represents a simple, accessible, and highly-flexible route to obtaining large databases of structured knowledge extracted from unstructured text. An online demo is available at http://www.matscholar.com/info-extraction.},
	urldate = {2025-06-05},
	publisher = {arXiv},
	author = {Dunn, Alexander and Dagdelen, John and Walker, Nicholas and Lee, Sanghoon and Rosen, Andrew S. and Ceder, Gerbrand and Persson, Kristin and Jain, Anubhav},
	month = dec,
	year = {2022},
	note = {arXiv:2212.05238 [cs]},
	keywords = {Computer Science - Computation and Language, Condensed Matter - Materials Science},
	file = {Preprint PDF:/Users/romeo/Zotero/storage/KUCKDM2F/Dunn et al. - 2022 - Structured information extraction from complex sci.pdf:application/pdf;Snapshot:/Users/romeo/Zotero/storage/CXQBSCLJ/2212.html:text/html},
}

@misc{wei_chatie_2024,
	title = {{ChatIE}: {Zero}-{Shot} {Information} {Extraction} via {Chatting} with {ChatGPT}},
	shorttitle = {{ChatIE}},
	url = {http://arxiv.org/abs/2302.10205},
	doi = {10.48550/arXiv.2302.10205},
	abstract = {Zero-shot information extraction (IE) aims to build IE systems from the unannotated text. It is challenging due to involving little human intervention. Challenging but worthwhile, zero-shot IE reduces the time and effort that data labeling takes. Recent efforts on large language models (LLMs, e.g., GPT-3, ChatGPT) show promising performance on zero-shot settings, thus inspiring us to explore prompt-based methods. In this work, we ask whether strong IE models can be constructed by directly prompting LLMs. Specifically, we transform the zero-shot IE task into a multi-turn question-answering problem with a two-stage framework (ChatIE). With the power of ChatGPT, we extensively evaluate our framework on three IE tasks: entity-relation triple extract, named entity recognition, and event extraction. Empirical results on six datasets across two languages show that ChatIE achieves impressive performance and even surpasses some full-shot models on several datasets (e.g., NYT11-HRL). We believe that our work could shed light on building IE models with limited resources.},
	urldate = {2025-06-05},
	publisher = {arXiv},
	author = {Wei, Xiang and Cui, Xingyu and Cheng, Ning and Wang, Xiaobin and Zhang, Xin and Huang, Shen and Xie, Pengjun and Xu, Jinan and Chen, Yufeng and Zhang, Meishan and Jiang, Yong and Han, Wenjuan},
	month = may,
	year = {2024},
	note = {arXiv:2302.10205 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/romeo/Zotero/storage/5YXWZLP5/Wei et al. - 2024 - ChatIE Zero-Shot Information Extraction via Chatt.pdf:application/pdf;Snapshot:/Users/romeo/Zotero/storage/EHGH3CR3/2302.html:text/html},
}

@misc{islam_llm-based_2025,
	title = {{LLM}-based {Prompt} {Ensemble} for {Reliable} {Medical} {Entity} {Recognition} from {EHRs}},
	url = {http://arxiv.org/abs/2505.08704},
	doi = {10.48550/arXiv.2505.08704},
	abstract = {Electronic Health Records (EHRs) are digital records of patient information, often containing unstructured clinical text. Named Entity Recognition (NER) is essential in EHRs for extracting key medical entities like problems, tests, and treatments to support downstream clinical applications. This paper explores prompt-based medical entity recognition using large language models (LLMs), specifically GPT-4o and DeepSeek-R1, guided by various prompt engineering techniques, including zero-shot, few-shot, and an ensemble approach. Among all strategies, GPT-4o with prompt ensemble achieved the highest classification performance with an F1-score of 0.95 and recall of 0.98, outperforming DeepSeek-R1 on the task. The ensemble method improved reliability by aggregating outputs through embedding-based similarity and majority voting.},
	urldate = {2025-06-14},
	publisher = {arXiv},
	author = {Islam, K. M. Sajjadul and Nipu, Ayesha Siddika and Wu, Jiawei and Madiraju, Praveen},
	month = may,
	year = {2025},
	note = {arXiv:2505.08704 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/romeo/Zotero/storage/ENSALNXQ/Islam et al. - 2025 - LLM-based Prompt Ensemble for Reliable Medical Ent.pdf:application/pdf;Snapshot:/Users/romeo/Zotero/storage/4HM5SYIL/2505.html:text/html},
}

@misc{villena_llmner_2024,
	title = {{llmNER}: ({Zero}{\textbar}{Few})-{Shot} {Named} {Entity} {Recognition}, {Exploiting} the {Power} of {Large} {Language} {Models}},
	shorttitle = {{llmNER}},
	url = {http://arxiv.org/abs/2406.04528},
	doi = {10.48550/arXiv.2406.04528},
	abstract = {Large language models (LLMs) allow us to generate high-quality human-like text. One interesting task in natural language processing (NLP) is named entity recognition (NER), which seeks to detect mentions of relevant information in documents. This paper presents llmNER, a Python library for implementing zero-shot and few-shot NER with LLMs; by providing an easy-to-use interface, llmNER can compose prompts, query the model, and parse the completion returned by the LLM. Also, the library enables the user to perform prompt engineering efficiently by providing a simple interface to test multiple variables. We validated our software on two NER tasks to show the library's flexibility. llmNER aims to push the boundaries of in-context learning research by removing the barrier of the prompting and parsing steps.},
	urldate = {2025-06-14},
	publisher = {arXiv},
	author = {Villena, Fabián and Miranda, Luis and Aracena, Claudio},
	month = jun,
	year = {2024},
	note = {arXiv:2406.04528 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/romeo/Zotero/storage/VM28DBAB/Villena et al. - 2024 - llmNER (ZeroFew)-Shot Named Entity Recognition, .pdf:application/pdf;Snapshot:/Users/romeo/Zotero/storage/EJYPISAY/2406.html:text/html},
}

@misc{hu_improving_2024,
	title = {Improving {Large} {Language} {Models} for {Clinical} {Named} {Entity} {Recognition} via {Prompt} {Engineering}},
	url = {http://arxiv.org/abs/2303.16416},
	doi = {10.48550/arXiv.2303.16416},
	abstract = {Objective: This study quantifies the capabilities of GPT-3.5 and GPT-4 for clinical named entity recognition (NER) tasks and proposes task-specific prompts to improve their performance. Materials and Methods: We evaluated these models on two clinical NER tasks: (1) to extract medical problems, treatments, and tests from clinical notes in the MTSamples corpus, following the 2010 i2b2 concept extraction shared task, and (2) identifying nervous system disorder-related adverse events from safety reports in the vaccine adverse event reporting system (VAERS). To improve the GPT models' performance, we developed a clinical task-specific prompt framework that includes (1) baseline prompts with task description and format specification, (2) annotation guideline-based prompts, (3) error analysis-based instructions, and (4) annotated samples for few-shot learning. We assessed each prompt's effectiveness and compared the models to BioClinicalBERT. Results: Using baseline prompts, GPT-3.5 and GPT-4 achieved relaxed F1 scores of 0.634, 0.804 for MTSamples, and 0.301, 0.593 for VAERS. Additional prompt components consistently improved model performance. When all four components were used, GPT-3.5 and GPT-4 achieved relaxed F1 socres of 0.794, 0.861 for MTSamples and 0.676, 0.736 for VAERS, demonstrating the effectiveness of our prompt framework. Although these results trail BioClinicalBERT (F1 of 0.901 for the MTSamples dataset and 0.802 for the VAERS), it is very promising considering few training samples are needed. Conclusion: While direct application of GPT models to clinical NER tasks falls short of optimal performance, our task-specific prompt framework, incorporating medical knowledge and training samples, significantly enhances GPT models' feasibility for potential clinical applications.},
	urldate = {2025-06-14},
	publisher = {arXiv},
	author = {Hu, Yan and Chen, Qingyu and Du, Jingcheng and Peng, Xueqing and Keloth, Vipina Kuttichi and Zuo, Xu and Zhou, Yujia and Li, Zehan and Jiang, Xiaoqian and Lu, Zhiyong and Roberts, Kirk and Xu, Hua},
	month = jan,
	year = {2024},
	note = {arXiv:2303.16416 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/romeo/Zotero/storage/ESY5GXM2/Hu et al. - 2024 - Improving Large Language Models for Clinical Named.pdf:application/pdf;Snapshot:/Users/romeo/Zotero/storage/CJBNURAR/2303.html:text/html},
}

@misc{noauthor_chatutil-yan-wittmann_nodate,
	title = {{ChatUtil}-{Yan}-{Wittmann}},
	url = {https://github.com/YanWittmann/automatic-document-classification/blob/main/src/main/java/de/yanwittmann/document/ai/ChatUtil.java},
	abstract = {OCR/AI-powered automated document renaming and sorting - YanWittmann/automatic-document-classification},
	language = {en},
	urldate = {2025-07-06},
	journal = {GitHub},
}

@misc{noauthor_f-score_2025,
	title = {F-score},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=F-score&oldid=1296408310},
	abstract = {In statistical analysis of binary classification and information retrieval systems, the F-score or F-measure is a measure of predictive performance. It is calculated from the precision and recall of the test, where the precision is the number of true positive results divided by the number of all samples predicted to be positive, including those not identified correctly, and the recall is the number of true positive results divided by the number of all samples that should have been identified as positive. Precision is also known as positive predictive value, and recall is also known as sensitivity in diagnostic binary classification.
The F1 score is the harmonic mean of the precision and recall. It thus symmetrically represents both precision and recall in one metric. The more generic




	F

	β




	\{{\textbackslash}displaystyle F\_\{{\textbackslash}beta \}\}

	score applies additional weights, valuing one of precision or recall more than the other.
The highest possible value of an F-score is 1.0, indicating perfect precision and recall, and the lowest possible value is 0, if the precision or the recall is zero.},
	language = {en},
	urldate = {2025-07-06},
	journal = {Wikipedia},
	month = jun,
	year = {2025},
	note = {Page Version ID: 1296408310},
}

@misc{noauthor_what_nodate,
	title = {What are tokens and how to count them? {\textbar} {OpenAI} {Help} {Center}},
	shorttitle = {What are tokens and how to count them?},
	url = {https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them},
	language = {en},
	urldate = {2025-07-06},
}

@misc{noauthor_scancode-toolkit-documentation_nodate,
	title = {{ScanCode}-{Toolkit}-{Documentation}},
	url = {https://scancode-toolkit.readthedocs.io/en/latest/getting-started/home.html},
	urldate = {2025-07-06},
	file = {Home — ScanCode-Toolkit documentation:/Users/romeo/Zotero/storage/TXFK69CE/home.html:text/html},
}

@misc{noauthor_ollama_nodate,
	title = {Ollama},
	url = {https://ollama.com},
	abstract = {Get up and running with large language models.},
	urldate = {2025-07-06},
	file = {Snapshot:/Users/romeo/Zotero/storage/CEGHQQ3F/ollama.com.html:text/html},
}

@misc{noauthor_metaeffekt-scancode-service_2025,
	title = {Metaeffekt-{ScanCode}-{Service}},
	copyright = {Apache-2.0},
	url = {https://github.com/org-metaeffekt/metaeffekt-scancode-service},
	abstract = {Local service for efficient integration of ScanCode Toolkit.},
	urldate = {2025-07-06},
	publisher = {\{metæffekt\}},
	month = may,
	year = {2025},
	note = {original-date: 2024-03-20T12:57:22Z},
	keywords = {scancode},
}
